{
  "template_id": "microservices-observability-stack-v1",
  "name": "Microservices Observability Stack",
  "version": "1.0.0",
  "description": "Production-grade observability stack with Prometheus metrics, OpenTelemetry distributed tracing, and Jaeger. Implements RED (Rate, Errors, Duration) pattern with SLO/SLI tracking.",
  "persona": "devops_engineer",
  "category": "observability",
  "complexity": "advanced",
  "tags": [
    "prometheus",
    "opentelemetry",
    "jaeger",
    "metrics",
    "tracing",
    "observability",
    "slo",
    "sli",
    "red-pattern",
    "python"
  ],
  "use_cases": [
    "Distributed tracing",
    "Performance monitoring",
    "SLO tracking",
    "Service mesh observability"
  ],
  "quality_score": 96,
  "security_score": 94,
  "performance_score": 93,
  "maintainability_score": 95,
  "extracted_from": "Conductor ML Platform (Production)",
  "implementation": {
    "metrics_collector.py": "\"\"\"\nPrometheus Metrics Collector for Maestro ML Platform\n\nProvides comprehensive metrics collection:\n- HTTP request metrics (RED pattern)\n- Business metrics (models, experiments, deployments)\n- System metrics (database, cache, queue)\n- Custom application metrics\n- SLO/SLI tracking\n\"\"\"\n\nfrom prometheus_client import (\n    Counter,\n    Histogram,\n    Gauge,\n    Summary,\n    Info,\n    generate_latest,\n    REGISTRY,\n    CollectorRegistry\n)\nfrom typing import Dict, Optional, Callable\nimport time\nimport functools\nfrom datetime import datetime\nimport logging\n\nlogger = logging.getLogger(__name__)\n\n\n# ============================================================================\n# HTTP Metrics (RED Pattern: Rate, Errors, Duration)\n# ============================================================================\n\n# Request rate\nhttp_requests_total = Counter(\n    'http_requests_total',\n    'Total HTTP requests',\n    ['method', 'endpoint', 'status']\n)\n\n# Request duration\nhttp_request_duration_seconds = Histogram(\n    'http_request_duration_seconds',\n    'HTTP request duration in seconds',\n    ['method', 'endpoint'],\n    buckets=(0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.0, 2.5, 5.0, 7.5, 10.0)\n)\n\n# Request size\nhttp_request_size_bytes = Summary(\n    'http_request_size_bytes',\n    'HTTP request size in bytes',\n    ['method', 'endpoint']\n)\n\n# Response size\nhttp_response_size_bytes = Summary(\n    'http_response_size_bytes',\n    'HTTP response size in bytes',\n    ['method', 'endpoint']\n)\n\n# In-flight requests\nhttp_requests_in_progress = Gauge(\n    'http_requests_in_progress',\n    'Number of HTTP requests in progress',\n    ['method', 'endpoint']\n)\n\n\n# ============================================================================\n# Business Metrics\n# ============================================================================\n\n# Models\nmodels_total = Gauge(\n    'models_total',\n    'Total number of models',\n    ['tenant_id', 'status']\n)\n\nmodels_created_total = Counter(\n    'models_created_total',\n    'Total models created',\n    ['tenant_id']\n)\n\nmodels_deleted_total = Counter(\n    'models_deleted_total',\n    'Total models deleted',\n    ['tenant_id']\n)\n\nmodel_training_duration_seconds = Histogram(\n    'model_training_duration_seconds',\n    'Model training duration in seconds',\n    ['tenant_id', 'model_type'],\n    buckets=(10, 30, 60, 300, 600, 1800, 3600, 7200, 14400, 28800)\n)\n\n# Experiments\nexperiments_total = Gauge(\n    'experiments_total',\n    'Total number of experiments',\n    ['tenant_id', 'status']\n)\n\nexperiments_created_total = Counter(\n    'experiments_created_total',\n    'Total experiments created',\n    ['tenant_id']\n)\n\nexperiment_runs_total = Counter(\n    'experiment_runs_total',\n    'Total experiment runs',\n    ['tenant_id', 'status']\n)\n\n# Deployments\ndeployments_total = Gauge(\n    'deployments_total',\n    'Total number of deployments',\n    ['tenant_id', 'environment', 'status']\n)\n\ndeployments_created_total = Counter(\n    'deployments_created_total',\n    'Total deployments created',\n    ['tenant_id', 'environment']\n)\n\ndeployment_duration_seconds = Histogram(\n    'deployment_duration_seconds',\n    'Deployment duration in seconds',\n    ['tenant_id', 'environment'],\n    buckets=(5, 10, 30, 60, 120, 300, 600)\n)\n\n# Predictions\npredictions_total = Counter(\n    'predictions_total',\n    'Total predictions made',\n    ['tenant_id', 'model_id', 'status']\n)\n\nprediction_latency_seconds = Histogram(\n    'prediction_latency_seconds',\n    'Prediction latency in seconds',\n    ['tenant_id', 'model_id'],\n    buckets=(0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0)\n)\n\n\n# ============================================================================\n# Database Metrics\n# ============================================================================\n\ndb_connections_total = Gauge(\n    'db_connections_total',\n    'Total database connections',\n    ['state']  # active, idle\n)\n\ndb_query_duration_seconds = Histogram(\n    'db_query_duration_seconds',\n    'Database query duration in seconds',\n    ['operation'],  # select, insert, update, delete\n    buckets=(0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0)\n)\n\ndb_queries_total = Counter(\n    'db_queries_total',\n    'Total database queries',\n    ['operation', 'status']\n)\n\ndb_connection_errors_total = Counter(\n    'db_connection_errors_total',\n    'Total database connection errors'\n)\n\ndb_pool_size = Gauge(\n    'db_pool_size',\n    'Database connection pool size'\n)\n\ndb_pool_overflow = Gauge(\n    'db_pool_overflow',\n    'Database connection pool overflow'\n)\n\n\n# ============================================================================\n# Cache Metrics\n# ============================================================================\n\ncache_hits_total = Counter(\n    'cache_hits_total',\n    'Total cache hits',\n    ['cache_name']\n)\n\ncache_misses_total = Counter(\n    'cache_misses_total',\n    'Total cache misses',\n    ['cache_name']\n)\n\ncache_operations_duration_seconds = Histogram(\n    'cache_operations_duration_seconds',\n    'Cache operation duration in seconds',\n    ['operation', 'cache_name'],\n    buckets=(0.0001, 0.0005, 0.001, 0.005, 0.01, 0.025, 0.05, 0.1)\n)\n\ncache_size_bytes = Gauge(\n    'cache_size_bytes',\n    'Cache size in bytes',\n    ['cache_name']\n)\n\ncache_evictions_total = Counter(\n    'cache_evictions_total',\n    'Total cache evictions',\n    ['cache_name']\n)\n\n\n# ============================================================================\n# Queue Metrics\n# ============================================================================\n\nqueue_messages_total = Gauge(\n    'queue_messages_total',\n    'Total messages in queue',\n    ['queue_name']\n)\n\nqueue_messages_processed_total = Counter(\n    'queue_messages_processed_total',\n    'Total messages processed',\n    ['queue_name', 'status']\n)\n\nqueue_processing_duration_seconds = Histogram(\n    'queue_processing_duration_seconds',\n    'Message processing duration in seconds',\n    ['queue_name'],\n    buckets=(0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0)\n)\n\n\n# ============================================================================\n# Rate Limiting Metrics\n# ============================================================================\n\nrate_limit_exceeded_total = Counter(\n    'rate_limit_exceeded_total',\n    'Total rate limit exceeded events',\n    ['tier']  # user, tenant, ip, global\n)\n\nrate_limit_current_usage = Gauge(\n    'rate_limit_current_usage',\n    'Current rate limit usage',\n    ['tier', 'identifier']\n)\n\n\n# ============================================================================\n# Tenant Metrics\n# ============================================================================\n\ntenant_requests_total = Counter(\n    'tenant_requests_total',\n    'Total requests per tenant',\n    ['tenant_id']\n)\n\ntenant_active_users = Gauge(\n    'tenant_active_users',\n    'Active users per tenant',\n    ['tenant_id']\n)\n\ntenant_storage_bytes = Gauge(\n    'tenant_storage_bytes',\n    'Storage used per tenant in bytes',\n    ['tenant_id']\n)\n\n\n# ============================================================================\n# SLO/SLI Metrics\n# ============================================================================\n\nslo_http_request_success_rate = Gauge(\n    'slo_http_request_success_rate',\n    'HTTP request success rate (SLI)',\n    ['service']\n)\n\nslo_http_request_latency_p99 = Gauge(\n    'slo_http_request_latency_p99',\n    'HTTP request p99 latency (SLI)',\n    ['service']\n)\n\nslo_availability = Gauge(\n    'slo_availability',\n    'Service availability (SLI)',\n    ['service']\n)\n\nslo_error_budget_remaining = Gauge(\n    'slo_error_budget_remaining',\n    'Error budget remaining (percentage)',\n    ['service']\n)\n\n\n# ============================================================================\n# Application Info\n# ============================================================================\n\napp_info = Info(\n    'maestro_ml_app',\n    'Application information'\n)\n\napp_info.info({\n    'version': '2.0.0',\n    'environment': 'production',\n    'deployment': 'kubernetes'\n})\n\napp_build_info = Gauge(\n    'maestro_ml_build_info',\n    'Build information',\n    ['version', 'git_commit', 'build_date']\n)\n\n\n# ============================================================================\n# Metrics Collector Class\n# ============================================================================\n\nclass MetricsCollector:\n    \"\"\"\n    Central metrics collector for the application\n\n    Usage:\n        collector = MetricsCollector()\n\n        # Record HTTP request\n        collector.record_http_request(\n            method=\"GET\",\n            endpoint=\"/models\",\n            status_code=200,\n            duration=0.123\n        )\n\n        # Record business event\n        collector.record_model_created(tenant_id=\"tenant-123\")\n    \"\"\"\n\n    def __init__(self):\n        self.start_time = time.time()\n\n    # HTTP Metrics\n    def record_http_request(\n        self,\n        method: str,\n        endpoint: str,\n        status_code: int,\n        duration: float,\n        request_size: Optional[int] = None,\n        response_size: Optional[int] = None\n    ):\n        \"\"\"Record HTTP request metrics\"\"\"\n        http_requests_total.labels(\n            method=method,\n            endpoint=endpoint,\n            status=str(status_code)\n        ).inc()\n\n        http_request_duration_seconds.labels(\n            method=method,\n            endpoint=endpoint\n        ).observe(duration)\n\n        if request_size:\n            http_request_size_bytes.labels(\n                method=method,\n                endpoint=endpoint\n            ).observe(request_size)\n\n        if response_size:\n            http_response_size_bytes.labels(\n                method=method,\n                endpoint=endpoint\n            ).observe(response_size)\n\n    def track_request_in_progress(self, method: str, endpoint: str):\n        \"\"\"Context manager to track in-progress requests\"\"\"\n        class RequestTracker:\n            def __enter__(self):\n                http_requests_in_progress.labels(\n                    method=method,\n                    endpoint=endpoint\n                ).inc()\n                return self\n\n            def __exit__(self, exc_type, exc_val, exc_tb):\n                http_requests_in_progress.labels(\n                    method=method,\n                    endpoint=endpoint\n                ).dec()\n\n        return RequestTracker()\n\n    # Business Metrics\n    def record_model_created(self, tenant_id: str):\n        \"\"\"Record model creation\"\"\"\n        models_created_total.labels(tenant_id=tenant_id).inc()\n\n    def record_model_deleted(self, tenant_id: str):\n        \"\"\"Record model deletion\"\"\"\n        models_deleted_total.labels(tenant_id=tenant_id).inc()\n\n    def record_model_training(self, tenant_id: str, model_type: str, duration: float):\n        \"\"\"Record model training duration\"\"\"\n        model_training_duration_seconds.labels(\n            tenant_id=tenant_id,\n            model_type=model_type\n        ).observe(duration)\n\n    def set_models_total(self, tenant_id: str, status: str, count: int):\n        \"\"\"Set total models gauge\"\"\"\n        models_total.labels(tenant_id=tenant_id, status=status).set(count)\n\n    def record_experiment_created(self, tenant_id: str):\n        \"\"\"Record experiment creation\"\"\"\n        experiments_created_total.labels(tenant_id=tenant_id).inc()\n\n    def record_experiment_run(self, tenant_id: str, status: str):\n        \"\"\"Record experiment run\"\"\"\n        experiment_runs_total.labels(tenant_id=tenant_id, status=status).inc()\n\n    def record_deployment_created(self, tenant_id: str, environment: str):\n        \"\"\"Record deployment creation\"\"\"\n        deployments_created_total.labels(\n            tenant_id=tenant_id,\n            environment=environment\n        ).inc()\n\n    def record_deployment_duration(self, tenant_id: str, environment: str, duration: float):\n        \"\"\"Record deployment duration\"\"\"\n        deployment_duration_seconds.labels(\n            tenant_id=tenant_id,\n            environment=environment\n        ).observe(duration)\n\n    def record_prediction(self, tenant_id: str, model_id: str, status: str, latency: float):\n        \"\"\"Record prediction\"\"\"\n        predictions_total.labels(\n            tenant_id=tenant_id,\n            model_id=model_id,\n            status=status\n        ).inc()\n\n        prediction_latency_seconds.labels(\n            tenant_id=tenant_id,\n            model_id=model_id\n        ).observe(latency)\n\n    # Database Metrics\n    def record_db_query(self, operation: str, duration: float, status: str = \"success\"):\n        \"\"\"Record database query\"\"\"\n        db_queries_total.labels(operation=operation, status=status).inc()\n        db_query_duration_seconds.labels(operation=operation).observe(duration)\n\n    def set_db_connections(self, active: int, idle: int):\n        \"\"\"Set database connection counts\"\"\"\n        db_connections_total.labels(state=\"active\").set(active)\n        db_connections_total.labels(state=\"idle\").set(idle)\n\n    def record_db_connection_error(self):\n        \"\"\"Record database connection error\"\"\"\n        db_connection_errors_total.inc()\n\n    # Cache Metrics\n    def record_cache_hit(self, cache_name: str):\n        \"\"\"Record cache hit\"\"\"\n        cache_hits_total.labels(cache_name=cache_name).inc()\n\n    def record_cache_miss(self, cache_name: str):\n        \"\"\"Record cache miss\"\"\"\n        cache_misses_total.labels(cache_name=cache_name).inc()\n\n    def record_cache_operation(self, operation: str, cache_name: str, duration: float):\n        \"\"\"Record cache operation duration\"\"\"\n        cache_operations_duration_seconds.labels(\n            operation=operation,\n            cache_name=cache_name\n        ).observe(duration)\n\n    # Rate Limiting Metrics\n    def record_rate_limit_exceeded(self, tier: str):\n        \"\"\"Record rate limit exceeded\"\"\"\n        rate_limit_exceeded_total.labels(tier=tier).inc()\n\n    def set_rate_limit_usage(self, tier: str, identifier: str, usage: int):\n        \"\"\"Set current rate limit usage\"\"\"\n        rate_limit_current_usage.labels(tier=tier, identifier=identifier).set(usage)\n\n    # Tenant Metrics\n    def record_tenant_request(self, tenant_id: str):\n        \"\"\"Record tenant request\"\"\"\n        tenant_requests_total.labels(tenant_id=tenant_id).inc()\n\n    def set_tenant_active_users(self, tenant_id: str, count: int):\n        \"\"\"Set active users for tenant\"\"\"\n        tenant_active_users.labels(tenant_id=tenant_id).set(count)\n\n    def set_tenant_storage(self, tenant_id: str, bytes_used: int):\n        \"\"\"Set storage used by tenant\"\"\"\n        tenant_storage_bytes.labels(tenant_id=tenant_id).set(bytes_used)\n\n    # SLO/SLI Metrics\n    def set_slo_success_rate(self, service: str, rate: float):\n        \"\"\"Set SLO success rate (0.0-1.0)\"\"\"\n        slo_http_request_success_rate.labels(service=service).set(rate)\n\n    def set_slo_latency_p99(self, service: str, latency: float):\n        \"\"\"Set SLO p99 latency\"\"\"\n        slo_http_request_latency_p99.labels(service=service).set(latency)\n\n    def set_slo_availability(self, service: str, availability: float):\n        \"\"\"Set SLO availability (0.0-1.0)\"\"\"\n        slo_availability.labels(service=service).set(availability)\n\n    def set_error_budget_remaining(self, service: str, percentage: float):\n        \"\"\"Set error budget remaining (0.0-100.0)\"\"\"\n        slo_error_budget_remaining.labels(service=service).set(percentage)\n\n    # Utility Methods\n    def get_uptime_seconds(self) -> float:\n        \"\"\"Get application uptime in seconds\"\"\"\n        return time.time() - self.start_time\n\n\n# ============================================================================\n# Decorators\n# ============================================================================\n\ndef track_time(metric: Histogram, **labels):\n    \"\"\"Decorator to track function execution time\"\"\"\n    def decorator(func: Callable):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            start = time.time()\n            try:\n                result = func(*args, **kwargs)\n                return result\n            finally:\n                duration = time.time() - start\n                metric.labels(**labels).observe(duration)\n        return wrapper\n    return decorator\n\n\ndef count_calls(metric: Counter, **labels):\n    \"\"\"Decorator to count function calls\"\"\"\n    def decorator(func: Callable):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            metric.labels(**labels).inc()\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n\n\n# ============================================================================\n# Global Instance\n# ============================================================================\n\nmetrics_collector = MetricsCollector()\n\n\n# ============================================================================\n# Metrics Endpoint\n# ============================================================================\n\ndef get_metrics() -> bytes:\n    \"\"\"\n    Get Prometheus metrics in text format\n\n    Returns:\n        Metrics in Prometheus text format\n    \"\"\"\n    return generate_latest(REGISTRY)\n\n\n# ============================================================================\n# Usage Examples\n# ============================================================================\n\n\"\"\"\n1. Record HTTP Request:\n\n   from monitoring.metrics_collector import metrics_collector\n\n   metrics_collector.record_http_request(\n       method=\"GET\",\n       endpoint=\"/models\",\n       status_code=200,\n       duration=0.123,\n       request_size=1024,\n       response_size=4096\n   )\n\n2. Track Request in Progress:\n\n   with metrics_collector.track_request_in_progress(\"GET\", \"/models\"):\n       # Do work\n       pass\n\n3. Record Business Events:\n\n   metrics_collector.record_model_created(tenant_id=\"tenant-123\")\n   metrics_collector.record_prediction(\n       tenant_id=\"tenant-123\",\n       model_id=\"model-456\",\n       status=\"success\",\n       latency=0.015\n   )\n\n4. Use Decorators:\n\n   from monitoring.metrics_collector import track_time, db_query_duration_seconds\n\n   @track_time(db_query_duration_seconds, operation=\"select\")\n   def fetch_models():\n       # Database query\n       pass\n\n5. Set SLO Metrics:\n\n   metrics_collector.set_slo_success_rate(\"api\", 0.999)\n   metrics_collector.set_slo_latency_p99(\"api\", 0.5)\n   metrics_collector.set_error_budget_remaining(\"api\", 95.5)\n\n6. Expose Metrics Endpoint (FastAPI):\n\n   from fastapi import FastAPI, Response\n   from monitoring.metrics_collector import get_metrics\n\n   app = FastAPI()\n\n   @app.get(\"/metrics\")\n   def metrics():\n       return Response(content=get_metrics(), media_type=\"text/plain\")\n\n7. Query Metrics (PromQL):\n\n   # Request rate\n   rate(http_requests_total[5m])\n\n   # Error rate\n   rate(http_requests_total{status=~\"5..\"}[5m])\n\n   # p99 latency\n   histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))\n\n   # Availability\n   sum(rate(http_requests_total{status!~\"5..\"}[5m])) /\n   sum(rate(http_requests_total[5m]))\n\"\"\"\n",
    "tracing.py": "\"\"\"\nOpenTelemetry Distributed Tracing Configuration\n\nProvides distributed tracing instrumentation for the Maestro ML platform.\nExports traces to Jaeger for visualization and analysis.\n\"\"\"\n\nimport os\nfrom typing import Optional\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.sdk.resources import Resource, SERVICE_NAME, SERVICE_VERSION\nfrom opentelemetry.exporter.jaeger.thrift import JaegerExporter\nfrom opentelemetry.instrumentation.fastapi import FastAPIInstrumentor\nfrom opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor\nfrom opentelemetry.instrumentation.httpx import HTTPXClientInstrumentor\nfrom opentelemetry.instrumentation.redis import RedisInstrumentor\nfrom fastapi import FastAPI\n\n\nclass TracingManager:\n    \"\"\"Manages OpenTelemetry tracing configuration and instrumentation.\"\"\"\n\n    def __init__(\n        self,\n        service_name: str = \"maestro-ml-api\",\n        service_version: str = \"1.0.0\",\n        jaeger_host: str = \"jaeger.observability.svc.cluster.local\",\n        jaeger_port: int = 6831,\n        enabled: bool = True\n    ):\n        \"\"\"\n        Initialize tracing manager.\n\n        Args:\n            service_name: Name of the service\n            service_version: Version of the service\n            jaeger_host: Jaeger agent hostname\n            jaeger_port: Jaeger agent port (UDP)\n            enabled: Whether tracing is enabled\n        \"\"\"\n        self.service_name = service_name\n        self.service_version = service_version\n        self.jaeger_host = jaeger_host\n        self.jaeger_port = jaeger_port\n        self.enabled = enabled\n        self._tracer_provider: Optional[TracerProvider] = None\n\n    def setup_tracing(self) -> Optional[TracerProvider]:\n        \"\"\"\n        Configure OpenTelemetry tracing with Jaeger exporter.\n\n        Returns:\n            TracerProvider instance if enabled, None otherwise\n        \"\"\"\n        if not self.enabled:\n            return None\n\n        # Create resource with service information\n        resource = Resource(attributes={\n            SERVICE_NAME: self.service_name,\n            SERVICE_VERSION: self.service_version,\n            \"deployment.environment\": os.getenv(\"ENVIRONMENT\", \"development\"),\n            \"service.namespace\": \"ml-platform\"\n        })\n\n        # Create tracer provider\n        self._tracer_provider = TracerProvider(resource=resource)\n\n        # Configure Jaeger exporter\n        jaeger_exporter = JaegerExporter(\n            agent_host_name=self.jaeger_host,\n            agent_port=self.jaeger_port,\n        )\n\n        # Add batch span processor\n        span_processor = BatchSpanProcessor(jaeger_exporter)\n        self._tracer_provider.add_span_processor(span_processor)\n\n        # Set global tracer provider\n        trace.set_tracer_provider(self._tracer_provider)\n\n        return self._tracer_provider\n\n    def instrument_fastapi(self, app: FastAPI):\n        \"\"\"\n        Instrument FastAPI application with automatic tracing.\n\n        Args:\n            app: FastAPI application instance\n        \"\"\"\n        if not self.enabled:\n            return\n\n        FastAPIInstrumentor.instrument_app(\n            app,\n            tracer_provider=self._tracer_provider,\n            excluded_urls=\"health,metrics\"  # Don't trace health/metrics endpoints\n        )\n\n    def instrument_sqlalchemy(self, engine):\n        \"\"\"\n        Instrument SQLAlchemy for database query tracing.\n\n        Args:\n            engine: SQLAlchemy engine instance\n        \"\"\"\n        if not self.enabled:\n            return\n\n        SQLAlchemyInstrumentor().instrument(\n            engine=engine,\n            tracer_provider=self._tracer_provider,\n        )\n\n    def instrument_httpx(self):\n        \"\"\"Instrument HTTPX for HTTP client tracing.\"\"\"\n        if not self.enabled:\n            return\n\n        HTTPXClientInstrumentor().instrument(\n            tracer_provider=self._tracer_provider\n        )\n\n    def instrument_redis(self):\n        \"\"\"Instrument Redis for cache tracing.\"\"\"\n        if not self.enabled:\n            return\n\n        RedisInstrumentor().instrument(\n            tracer_provider=self._tracer_provider\n        )\n\n    def get_tracer(self, name: str = __name__) -> trace.Tracer:\n        \"\"\"\n        Get a tracer instance for manual instrumentation.\n\n        Args:\n            name: Name for the tracer\n\n        Returns:\n            Tracer instance\n        \"\"\"\n        return trace.get_tracer(name)\n\n\ndef configure_tracing(\n    app: FastAPI,\n    service_name: str = \"maestro-ml-api\",\n    jaeger_host: Optional[str] = None\n) -> TracingManager:\n    \"\"\"\n    Configure distributed tracing for the application.\n\n    Args:\n        app: FastAPI application\n        service_name: Service name for traces\n        jaeger_host: Jaeger agent host (defaults to env or cluster DNS)\n\n    Returns:\n        TracingManager instance\n    \"\"\"\n    # Get configuration from environment\n    enabled = os.getenv(\"TRACING_ENABLED\", \"true\").lower() == \"true\"\n    jaeger_host = jaeger_host or os.getenv(\n        \"JAEGER_AGENT_HOST\",\n        \"jaeger.observability.svc.cluster.local\"\n    )\n    jaeger_port = int(os.getenv(\"JAEGER_AGENT_PORT\", \"6831\"))\n\n    # Create tracing manager\n    tracing_manager = TracingManager(\n        service_name=service_name,\n        jaeger_host=jaeger_host,\n        jaeger_port=jaeger_port,\n        enabled=enabled\n    )\n\n    # Setup tracing\n    tracing_manager.setup_tracing()\n\n    # Instrument FastAPI\n    tracing_manager.instrument_fastapi(app)\n\n    # Instrument HTTP clients\n    tracing_manager.instrument_httpx()\n\n    # Instrument Redis (if available)\n    try:\n        tracing_manager.instrument_redis()\n    except Exception:\n        pass  # Redis not available\n\n    return tracing_manager\n\n\n# Context manager for custom spans\nclass trace_span:\n    \"\"\"Context manager for creating custom trace spans.\"\"\"\n\n    def __init__(self, name: str, attributes: Optional[dict] = None):\n        \"\"\"\n        Initialize span context manager.\n\n        Args:\n            name: Span name\n            attributes: Optional span attributes\n        \"\"\"\n        self.name = name\n        self.attributes = attributes or {}\n        self.span = None\n\n    def __enter__(self):\n        tracer = trace.get_tracer(__name__)\n        self.span = tracer.start_span(self.name)\n\n        # Set attributes\n        for key, value in self.attributes.items():\n            self.span.set_attribute(key, value)\n\n        return self.span\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is not None:\n            # Record exception in span\n            self.span.record_exception(exc_val)\n            self.span.set_status(\n                trace.Status(trace.StatusCode.ERROR, str(exc_val))\n            )\n\n        self.span.end()\n        return False\n\n\n# Decorator for tracing functions\ndef traced(span_name: Optional[str] = None, attributes: Optional[dict] = None):\n    \"\"\"\n    Decorator to trace function execution.\n\n    Args:\n        span_name: Custom span name (defaults to function name)\n        attributes: Additional span attributes\n\n    Example:\n        @traced(\"process_model\")\n        async def process_model(model_id: str):\n            ...\n    \"\"\"\n    def decorator(func):\n        async def async_wrapper(*args, **kwargs):\n            name = span_name or func.__name__\n            attrs = attributes or {}\n\n            with trace_span(name, attrs):\n                return await func(*args, **kwargs)\n\n        def sync_wrapper(*args, **kwargs):\n            name = span_name or func.__name__\n            attrs = attributes or {}\n\n            with trace_span(name, attrs):\n                return func(*args, **kwargs)\n\n        # Return appropriate wrapper\n        import asyncio\n        if asyncio.iscoroutinefunction(func):\n            return async_wrapper\n        else:\n            return sync_wrapper\n\n    return decorator\n",
    "README.md": "# Microservices Observability Stack\n\nProduction-grade observability with Prometheus and OpenTelemetry.\n\n## Features\n\n- **Prometheus Metrics**: RED pattern (Rate, Errors, Duration)\n- **Distributed Tracing**: OpenTelemetry + Jaeger\n- **SLO/SLI Tracking**: Error budget monitoring\n- **Business Metrics**: Custom application metrics\n\n## Usage\n\n```python\nfrom metrics_collector import metrics_collector\nfrom tracing import configure_tracing\n\n# Setup metrics\nmetrics_collector.record_http_request(\n    method=\"GET\", \n    endpoint=\"/api/models\",\n    status_code=200,\n    duration=0.123\n)\n\n# Setup tracing\napp = FastAPI()\nconfigure_tracing(app, service_name=\"ml-api\")\n```\n\n## Configuration\n\n```yaml\n# docker-compose.yml\nservices:\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n\n  jaeger:\n    image: jaegertracing/all-in-one:latest\n    ports:\n      - \"16686:16686\"  # UI\n      - \"6831:6831/udp\"  # Agent\n```\n"
  },
  "dependencies": {
    "python": ">=3.8",
    "runtime": [
      "prometheus-client>=0.17.0",
      "opentelemetry-api>=1.20.0",
      "opentelemetry-sdk>=1.20.0",
      "opentelemetry-instrumentation-fastapi>=0.41b0",
      "opentelemetry-instrumentation-sqlalchemy>=0.41b0",
      "opentelemetry-instrumentation-httpx>=0.41b0",
      "opentelemetry-instrumentation-redis>=0.41b0",
      "opentelemetry-exporter-jaeger>=1.20.0"
    ],
    "dev": []
  },
  "metadata": {
    "created_at": "2025-10-13T00:00:00Z",
    "curated": true,
    "production_ready": true
  }
}