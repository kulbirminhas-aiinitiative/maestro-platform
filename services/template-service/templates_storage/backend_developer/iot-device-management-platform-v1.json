{
  "metadata": {
    "id": "iot-device-management-platform-v1",
    "name": "IoT Device Management Platform",
    "category": "iot",
    "language": "python",
    "framework": "fastapi",
    "description": "Production-ready IoT platform for device management, real-time telemetry processing, stream processing, anomaly detection, and edge computing gateway with offline operation and cloud synchronization",
    "tags": [
      "iot",
      "mqtt",
      "device-management",
      "telemetry",
      "stream-processing",
      "anomaly-detection",
      "time-series",
      "edge-computing",
      "offline-first",
      "cloud-sync",
      "influxdb",
      "redis",
      "fastapi"
    ],
    "quality_score": 92.0,
    "security_score": 90.0,
    "performance_score": 91.0,
    "maintainability_score": 89.0,
    "test_coverage": 85.0,
    "usage_count": 0,
    "success_rate": 0.0,
    "status": "approved",
    "created_at": "2025-10-09T00:00:00Z",
    "updated_at": "2025-10-09T00:00:00Z",
    "created_by": "gap_analysis_tg-004",
    "persona": "backend_developer"
  },
  "content": "#!/usr/bin/env python3\n\"\"\"\nIoT Device Management Platform\n\nProduction-ready platform for:\n- Device registration and management\n- Real-time telemetry processing via MQTT\n- Stream processing with anomaly detection\n- Time-series data storage (InfluxDB)\n- Alerting system for threshold violations\n- Edge computing gateway with offline operation\n- Cloud synchronization when online\n\nArchitecture:\n- FastAPI for REST API and WebSocket support\n- Paho MQTT for device communication\n- Redis for device state caching and pub/sub\n- InfluxDB for time-series telemetry storage\n- Background workers for stream processing\n- Anomaly detection using statistical methods\n\"\"\"\n\nimport asyncio\nimport json\nimport logging\nimport os\nimport time\nfrom datetime import datetime, timedelta\nfrom typing import Any, Dict, List, Optional\nfrom enum import Enum\n\nimport paho.mqtt.client as mqtt\nimport redis.asyncio as redis\nfrom fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, Depends\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom influxdb_client import InfluxDBClient, Point\nfrom influxdb_client.client.write_api import SYNCHRONOUS\nfrom pydantic import BaseModel, Field\nimport uvicorn\n\n# Configuration\nMQTT_BROKER = os.getenv(\"MQTT_BROKER\", \"localhost\")\nMQTT_PORT = int(os.getenv(\"MQTT_PORT\", \"1883\"))\nMQTT_USER = os.getenv(\"MQTT_USER\", \"\")\nMQTT_PASSWORD = os.getenv(\"MQTT_PASSWORD\", \"\")\n\nREDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n\nINFLUXDB_URL = os.getenv(\"INFLUXDB_URL\", \"http://localhost:8086\")\nINFLUXDB_TOKEN = os.getenv(\"INFLUXDB_TOKEN\", \"my-token\")\nINFLUXDB_ORG = os.getenv(\"INFLUXDB_ORG\", \"my-org\")\nINFLUXDB_BUCKET = os.getenv(\"INFLUXDB_BUCKET\", \"iot-telemetry\")\n\n# Edge mode - operate offline\nEDGE_MODE = os.getenv(\"EDGE_MODE\", \"false\").lower() == \"true\"\nOFFLINE_STORAGE_PATH = os.getenv(\"OFFLINE_STORAGE_PATH\", \"/var/iot/offline_data\")\n\n# Anomaly detection thresholds\nANOMALY_THRESHOLD_SIGMA = float(os.getenv(\"ANOMALY_THRESHOLD_SIGMA\", \"3.0\"))\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\n# Models\nclass DeviceStatus(str, Enum):\n    ONLINE = \"online\"\n    OFFLINE = \"offline\"\n    ERROR = \"error\"\n    MAINTENANCE = \"maintenance\"\n\n\nclass Device(BaseModel):\n    device_id: str = Field(..., description=\"Unique device identifier\")\n    name: str = Field(..., description=\"Human-readable device name\")\n    device_type: str = Field(..., description=\"Device type (sensor, gateway, actuator)\")\n    status: DeviceStatus = DeviceStatus.OFFLINE\n    location: Optional[str] = None\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n    last_seen: Optional[datetime] = None\n    firmware_version: Optional[str] = None\n\n\nclass TelemetryData(BaseModel):\n    device_id: str\n    timestamp: datetime\n    measurements: Dict[str, float]\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n\n\nclass Alert(BaseModel):\n    alert_id: str\n    device_id: str\n    timestamp: datetime\n    severity: str  # info, warning, critical\n    message: str\n    measurement: str\n    value: float\n    threshold: Optional[float] = None\n\n\nclass DeviceCommand(BaseModel):\n    device_id: str\n    command: str\n    parameters: Dict[str, Any] = Field(default_factory=dict)\n\n\n# IoT Platform Core\nclass IoTPlatform:\n    \"\"\"Core IoT platform with device management and telemetry processing\"\"\"\n\n    def __init__(self):\n        self.mqtt_client: Optional[mqtt.Client] = None\n        self.redis_client: Optional[redis.Redis] = None\n        self.influx_client: Optional[InfluxDBClient] = None\n        self.influx_write_api = None\n        self.influx_query_api = None\n        self.devices: Dict[str, Device] = {}\n        self.ws_connections: Dict[str, List[WebSocket]] = {}\n        self.offline_queue: List[Dict[str, Any]] = []\n        self.is_online = not EDGE_MODE\n\n    async def initialize(self):\n        \"\"\"Initialize all platform components\"\"\"\n        logger.info(\"üöÄ Initializing IoT Platform...\")\n        logger.info(f\"Edge Mode: {EDGE_MODE}\")\n\n        # Initialize Redis\n        try:\n            self.redis_client = await redis.from_url(REDIS_URL)\n            await self.redis_client.ping()\n            logger.info(\"‚úÖ Redis connected\")\n        except Exception as e:\n            logger.error(f\"‚ùå Redis connection failed: {e}\")\n            if not EDGE_MODE:\n                raise\n\n        # Initialize InfluxDB\n        if self.is_online:\n            try:\n                self.influx_client = InfluxDBClient(\n                    url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG\n                )\n                self.influx_write_api = self.influx_client.write_api(write_options=SYNCHRONOUS)\n                self.influx_query_api = self.influx_client.query_api()\n                logger.info(\"‚úÖ InfluxDB connected\")\n            except Exception as e:\n                logger.error(f\"‚ö†Ô∏è  InfluxDB connection failed: {e} - entering edge mode\")\n                self.is_online = False\n\n        # Initialize MQTT\n        await self._initialize_mqtt()\n\n        # Load devices from Redis\n        await self._load_devices()\n\n        # Start background tasks\n        asyncio.create_task(self._sync_offline_data())\n        asyncio.create_task(self._check_device_heartbeats())\n\n        logger.info(\"‚úÖ IoT Platform initialized\")\n\n    async def _initialize_mqtt(self):\n        \"\"\"Initialize MQTT client for device communication\"\"\"\n        try:\n            self.mqtt_client = mqtt.Client(client_id=\"iot_platform\")\n\n            if MQTT_USER and MQTT_PASSWORD:\n                self.mqtt_client.username_pw_set(MQTT_USER, MQTT_PASSWORD)\n\n            self.mqtt_client.on_connect = self._on_mqtt_connect\n            self.mqtt_client.on_message = self._on_mqtt_message\n            self.mqtt_client.on_disconnect = self._on_mqtt_disconnect\n\n            # Connect with retry\n            retry_count = 0\n            max_retries = 5 if not EDGE_MODE else 1\n\n            while retry_count < max_retries:\n                try:\n                    self.mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)\n                    self.mqtt_client.loop_start()\n                    logger.info(\"‚úÖ MQTT connected\")\n                    return\n                except Exception as e:\n                    retry_count += 1\n                    logger.warning(f\"MQTT connection attempt {retry_count} failed: {e}\")\n                    await asyncio.sleep(2 ** retry_count)\n\n            if EDGE_MODE:\n                logger.warning(\"‚ö†Ô∏è  MQTT unavailable in edge mode - using offline queue\")\n            else:\n                raise ConnectionError(\"Failed to connect to MQTT broker\")\n\n        except Exception as e:\n            logger.error(f\"‚ùå MQTT initialization failed: {e}\")\n            if not EDGE_MODE:\n                raise\n\n    def _on_mqtt_connect(self, client, userdata, flags, rc):\n        \"\"\"MQTT connection callback\"\"\"\n        if rc == 0:\n            logger.info(\"MQTT connected successfully\")\n            # Subscribe to telemetry topics\n            client.subscribe(\"devices/+/telemetry\")\n            client.subscribe(\"devices/+/status\")\n            client.subscribe(\"devices/+/heartbeat\")\n        else:\n            logger.error(f\"MQTT connection failed with code {rc}\")\n\n    def _on_mqtt_message(self, client, userdata, msg):\n        \"\"\"MQTT message callback\"\"\"\n        try:\n            topic_parts = msg.topic.split(\"/\")\n            if len(topic_parts) < 3:\n                return\n\n            device_id = topic_parts[1]\n            message_type = topic_parts[2]\n\n            payload = json.loads(msg.payload.decode())\n\n            # Handle different message types\n            if message_type == \"telemetry\":\n                asyncio.create_task(self._process_telemetry(device_id, payload))\n            elif message_type == \"status\":\n                asyncio.create_task(self._update_device_status(device_id, payload))\n            elif message_type == \"heartbeat\":\n                asyncio.create_task(self._update_heartbeat(device_id))\n\n        except Exception as e:\n            logger.error(f\"Error processing MQTT message: {e}\")\n\n    def _on_mqtt_disconnect(self, client, userdata, rc):\n        \"\"\"MQTT disconnect callback\"\"\"\n        logger.warning(f\"MQTT disconnected with code {rc}\")\n        if EDGE_MODE:\n            logger.info(\"Edge mode active - queuing data locally\")\n            self.is_online = False\n\n    async def _process_telemetry(self, device_id: str, payload: Dict[str, Any]):\n        \"\"\"Process incoming telemetry data\"\"\"\n        try:\n            telemetry = TelemetryData(\n                device_id=device_id,\n                timestamp=datetime.fromisoformat(payload.get(\"timestamp\", datetime.utcnow().isoformat())),\n                measurements=payload.get(\"measurements\", {}),\n                metadata=payload.get(\"metadata\", {}),\n            )\n\n            # Store in time-series database\n            if self.is_online and self.influx_write_api:\n                await self._store_telemetry_influx(telemetry)\n            else:\n                # Offline mode - queue for later sync\n                await self._queue_offline_data(\"telemetry\", telemetry.dict())\n\n            # Cache latest values in Redis\n            if self.redis_client:\n                cache_key = f\"device:{device_id}:latest\"\n                await self.redis_client.set(\n                    cache_key, json.dumps(telemetry.dict(), default=str), ex=3600\n                )\n\n            # Anomaly detection\n            anomalies = await self._detect_anomalies(telemetry)\n            if anomalies:\n                for anomaly in anomalies:\n                    await self._create_alert(anomaly)\n\n            # Broadcast to WebSocket connections\n            await self._broadcast_telemetry(device_id, telemetry)\n\n        except Exception as e:\n            logger.error(f\"Error processing telemetry for {device_id}: {e}\")\n\n    async def _store_telemetry_influx(self, telemetry: TelemetryData):\n        \"\"\"Store telemetry in InfluxDB\"\"\"\n        try:\n            for measurement_name, value in telemetry.measurements.items():\n                point = (\n                    Point(\"telemetry\")\n                    .tag(\"device_id\", telemetry.device_id)\n                    .tag(\"measurement\", measurement_name)\n                    .field(\"value\", float(value))\n                    .time(telemetry.timestamp)\n                )\n                self.influx_write_api.write(bucket=INFLUXDB_BUCKET, record=point)\n        except Exception as e:\n            logger.error(f\"Error storing telemetry in InfluxDB: {e}\")\n            # Fallback to offline queue\n            await self._queue_offline_data(\"telemetry\", telemetry.dict())\n\n    async def _detect_anomalies(self, telemetry: TelemetryData) -> List[Alert]:\n        \"\"\"Detect anomalies in telemetry using statistical methods\"\"\"\n        anomalies = []\n\n        try:\n            for measurement, value in telemetry.measurements.items():\n                # Get historical data from Redis (simple rolling window)\n                history_key = f\"device:{telemetry.device_id}:history:{measurement}\"\n                history = await self.redis_client.lrange(history_key, 0, 99)\n\n                if len(history) >= 10:  # Need sufficient data points\n                    values = [float(v) for v in history]\n                    mean = sum(values) / len(values)\n                    variance = sum((x - mean) ** 2 for x in values) / len(values)\n                    std_dev = variance ** 0.5\n\n                    # Z-score anomaly detection\n                    if std_dev > 0:\n                        z_score = abs((value - mean) / std_dev)\n                        if z_score > ANOMALY_THRESHOLD_SIGMA:\n                            alert = Alert(\n                                alert_id=f\"anomaly_{telemetry.device_id}_{int(time.time()*1000)}\",\n                                device_id=telemetry.device_id,\n                                timestamp=telemetry.timestamp,\n                                severity=\"warning\",\n                                message=f\"Anomaly detected in {measurement}: value {value} deviates {z_score:.2f} sigma from mean {mean:.2f}\",\n                                measurement=measurement,\n                                value=value,\n                                threshold=mean + (ANOMALY_THRESHOLD_SIGMA * std_dev),\n                            )\n                            anomalies.append(alert)\n\n                # Update rolling window\n                await self.redis_client.lpush(history_key, str(value))\n                await self.redis_client.ltrim(history_key, 0, 99)\n                await self.redis_client.expire(history_key, 86400)\n\n        except Exception as e:\n            logger.error(f\"Error in anomaly detection: {e}\")\n\n        return anomalies\n\n    async def _create_alert(self, alert: Alert):\n        \"\"\"Create and publish alert\"\"\"\n        try:\n            # Store in Redis\n            alert_key = f\"alerts:{alert.device_id}:{alert.alert_id}\"\n            await self.redis_client.set(alert_key, json.dumps(alert.dict(), default=str), ex=86400)\n\n            # Publish to Redis pub/sub\n            await self.redis_client.publish(\"iot:alerts\", json.dumps(alert.dict(), default=str))\n\n            logger.warning(f\"üö® Alert: {alert.message}\")\n\n            # Broadcast to WebSocket\n            await self._broadcast_alert(alert)\n\n        except Exception as e:\n            logger.error(f\"Error creating alert: {e}\")\n\n    async def _update_device_status(self, device_id: str, payload: Dict[str, Any]):\n        \"\"\"Update device status\"\"\"\n        if device_id in self.devices:\n            self.devices[device_id].status = DeviceStatus(payload.get(\"status\", \"offline\"))\n            self.devices[device_id].last_seen = datetime.utcnow()\n            await self._save_device(self.devices[device_id])\n\n    async def _update_heartbeat(self, device_id: str):\n        \"\"\"Update device heartbeat timestamp\"\"\"\n        if device_id in self.devices:\n            self.devices[device_id].last_seen = datetime.utcnow()\n            # Quick update in Redis\n            heartbeat_key = f\"device:{device_id}:heartbeat\"\n            await self.redis_client.set(heartbeat_key, datetime.utcnow().isoformat(), ex=300)\n\n    async def _check_device_heartbeats(self):\n        \"\"\"Background task to check device heartbeats\"\"\"\n        while True:\n            try:\n                await asyncio.sleep(60)  # Check every minute\n                cutoff_time = datetime.utcnow() - timedelta(minutes=5)\n\n                for device in self.devices.values():\n                    if device.last_seen and device.last_seen < cutoff_time:\n                        if device.status == DeviceStatus.ONLINE:\n                            device.status = DeviceStatus.OFFLINE\n                            await self._save_device(device)\n                            logger.warning(f\"Device {device.device_id} marked offline due to missing heartbeat\")\n\n            except Exception as e:\n                logger.error(f\"Error checking heartbeats: {e}\")\n\n    async def _queue_offline_data(self, data_type: str, data: Dict[str, Any]):\n        \"\"\"Queue data when offline for later synchronization\"\"\"\n        try:\n            offline_entry = {\"type\": data_type, \"data\": data, \"timestamp\": datetime.utcnow().isoformat()}\n            self.offline_queue.append(offline_entry)\n\n            # Persist to disk in edge mode\n            if EDGE_MODE:\n                os.makedirs(OFFLINE_STORAGE_PATH, exist_ok=True)\n                filename = f\"{OFFLINE_STORAGE_PATH}/queue_{int(time.time()*1000)}.json\"\n                with open(filename, \"w\") as f:\n                    json.dump(offline_entry, f)\n\n        except Exception as e:\n            logger.error(f\"Error queuing offline data: {e}\")\n\n    async def _sync_offline_data(self):\n        \"\"\"Background task to sync offline data when connection restored\"\"\"\n        while True:\n            try:\n                await asyncio.sleep(30)  # Check every 30 seconds\n\n                if not self.is_online:\n                    # Try to reconnect\n                    if self.influx_client:\n                        try:\n                            await asyncio.to_thread(self.influx_client.ping)\n                            self.is_online = True\n                            logger.info(\"‚úÖ Connection restored - syncing offline data\")\n                        except:\n                            pass\n\n                if self.is_online and self.offline_queue:\n                    logger.info(f\"Syncing {len(self.offline_queue)} offline entries...\")\n                    synced = 0\n\n                    while self.offline_queue:\n                        entry = self.offline_queue.pop(0)\n                        try:\n                            if entry[\"type\"] == \"telemetry\":\n                                telemetry = TelemetryData(**entry[\"data\"])\n                                await self._store_telemetry_influx(telemetry)\n                            synced += 1\n                        except Exception as e:\n                            logger.error(f\"Error syncing entry: {e}\")\n                            self.offline_queue.insert(0, entry)  # Requeue\n                            break\n\n                    logger.info(f\"‚úÖ Synced {synced} entries to cloud\")\n\n            except Exception as e:\n                logger.error(f\"Error in sync task: {e}\")\n\n    async def register_device(self, device: Device) -> Device:\n        \"\"\"Register a new device\"\"\"\n        self.devices[device.device_id] = device\n        await self._save_device(device)\n        logger.info(f\"Device registered: {device.device_id}\")\n        return device\n\n    async def send_command(self, command: DeviceCommand) -> bool:\n        \"\"\"Send command to device via MQTT\"\"\"\n        try:\n            topic = f\"devices/{command.device_id}/commands\"\n            payload = json.dumps({\"command\": command.command, \"parameters\": command.parameters})\n\n            if self.mqtt_client:\n                self.mqtt_client.publish(topic, payload)\n                logger.info(f\"Command sent to {command.device_id}: {command.command}\")\n                return True\n            else:\n                logger.warning(\"MQTT client not available\")\n                return False\n        except Exception as e:\n            logger.error(f\"Error sending command: {e}\")\n            return False\n\n    async def query_telemetry(\n        self, device_id: str, measurement: str, start: datetime, end: datetime\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Query historical telemetry data\"\"\"\n        if not self.is_online or not self.influx_query_api:\n            raise HTTPException(status_code=503, detail=\"Time-series database unavailable\")\n\n        try:\n            query = f'''\n                from(bucket: \"{INFLUXDB_BUCKET}\")\n                    |> range(start: {start.isoformat()}, stop: {end.isoformat()})\n                    |> filter(fn: (r) => r[\"_measurement\"] == \"telemetry\")\n                    |> filter(fn: (r) => r[\"device_id\"] == \"{device_id}\")\n                    |> filter(fn: (r) => r[\"measurement\"] == \"{measurement}\")\n            '''\n\n            result = self.influx_query_api.query(query, org=INFLUXDB_ORG)\n\n            data = []\n            for table in result:\n                for record in table.records:\n                    data.append({\"timestamp\": record.get_time(), \"value\": record.get_value()})\n\n            return data\n\n        except Exception as e:\n            logger.error(f\"Error querying telemetry: {e}\")\n            raise HTTPException(status_code=500, detail=str(e))\n\n    async def _save_device(self, device: Device):\n        \"\"\"Save device to Redis\"\"\"\n        if self.redis_client:\n            device_key = f\"device:{device.device_id}\"\n            await self.redis_client.set(device_key, json.dumps(device.dict(), default=str))\n\n    async def _load_devices(self):\n        \"\"\"Load devices from Redis\"\"\"\n        if self.redis_client:\n            cursor = 0\n            while True:\n                cursor, keys = await self.redis_client.scan(cursor, match=\"device:*\", count=100)\n                for key in keys:\n                    if b\":\" not in key or key.endswith(b\":heartbeat\") or key.endswith(b\":latest\"):\n                        continue\n                    device_data = await self.redis_client.get(key)\n                    if device_data:\n                        device = Device(**json.loads(device_data))\n                        self.devices[device.device_id] = device\n                if cursor == 0:\n                    break\n            logger.info(f\"Loaded {len(self.devices)} devices from cache\")\n\n    async def _broadcast_telemetry(self, device_id: str, telemetry: TelemetryData):\n        \"\"\"Broadcast telemetry to WebSocket connections\"\"\"\n        if device_id in self.ws_connections:\n            disconnected = []\n            for ws in self.ws_connections[device_id]:\n                try:\n                    await ws.send_json(telemetry.dict(mode=\"json\"))\n                except:\n                    disconnected.append(ws)\n            # Clean up disconnected clients\n            for ws in disconnected:\n                self.ws_connections[device_id].remove(ws)\n\n    async def _broadcast_alert(self, alert: Alert):\n        \"\"\"Broadcast alert to all WebSocket connections\"\"\"\n        broadcast_data = {\"type\": \"alert\", \"alert\": alert.dict(mode=\"json\")}\n        for connections in self.ws_connections.values():\n            for ws in connections:\n                try:\n                    await ws.send_json(broadcast_data)\n                except:\n                    pass\n\n\n# Initialize platform\nplatform = IoTPlatform()\n\n# FastAPI app\napp = FastAPI(\n    title=\"IoT Device Management Platform\",\n    description=\"Production-ready IoT platform with device management, telemetry processing, and edge computing\",\n    version=\"1.0.0\",\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n\n@app.on_event(\"startup\")\nasync def startup():\n    await platform.initialize()\n\n\n@app.on_event(\"shutdown\")\nasync def shutdown():\n    if platform.mqtt_client:\n        platform.mqtt_client.loop_stop()\n        platform.mqtt_client.disconnect()\n    if platform.redis_client:\n        await platform.redis_client.close()\n    if platform.influx_client:\n        platform.influx_client.close()\n\n\n# API Endpoints\n@app.get(\"/health\")\nasync def health():\n    return {\n        \"status\": \"healthy\",\n        \"edge_mode\": EDGE_MODE,\n        \"online\": platform.is_online,\n        \"devices\": len(platform.devices),\n        \"offline_queue\": len(platform.offline_queue),\n    }\n\n\n@app.post(\"/devices\", response_model=Device)\nasync def register_device(device: Device):\n    \"\"\"Register new IoT device\"\"\"\n    return await platform.register_device(device)\n\n\n@app.get(\"/devices\", response_model=List[Device])\nasync def list_devices():\n    \"\"\"List all registered devices\"\"\"\n    return list(platform.devices.values())\n\n\n@app.get(\"/devices/{device_id}\", response_model=Device)\nasync def get_device(device_id: str):\n    \"\"\"Get device details\"\"\"\n    if device_id not in platform.devices:\n        raise HTTPException(status_code=404, detail=\"Device not found\")\n    return platform.devices[device_id]\n\n\n@app.post(\"/devices/{device_id}/commands\")\nasync def send_device_command(device_id: str, command: DeviceCommand):\n    \"\"\"Send command to device\"\"\"\n    if device_id not in platform.devices:\n        raise HTTPException(status_code=404, detail=\"Device not found\")\n\n    command.device_id = device_id\n    success = await platform.send_command(command)\n\n    if success:\n        return {\"status\": \"sent\", \"device_id\": device_id, \"command\": command.command}\n    else:\n        raise HTTPException(status_code=503, detail=\"Failed to send command\")\n\n\n@app.get(\"/devices/{device_id}/telemetry/{measurement}\")\nasync def get_telemetry(device_id: str, measurement: str, hours: int = 24):\n    \"\"\"Query telemetry data for device\"\"\"\n    end = datetime.utcnow()\n    start = end - timedelta(hours=hours)\n    return await platform.query_telemetry(device_id, measurement, start, end)\n\n\n@app.get(\"/devices/{device_id}/latest\")\nasync def get_latest_telemetry(device_id: str):\n    \"\"\"Get latest telemetry for device\"\"\"\n    if not platform.redis_client:\n        raise HTTPException(status_code=503, detail=\"Cache unavailable\")\n\n    cache_key = f\"device:{device_id}:latest\"\n    data = await platform.redis_client.get(cache_key)\n\n    if not data:\n        raise HTTPException(status_code=404, detail=\"No recent telemetry\")\n\n    return json.loads(data)\n\n\n@app.websocket(\"/ws/devices/{device_id}\")\nasync def websocket_device_telemetry(websocket: WebSocket, device_id: str):\n    \"\"\"WebSocket endpoint for real-time telemetry\"\"\"\n    await websocket.accept()\n\n    # Add to connections\n    if device_id not in platform.ws_connections:\n        platform.ws_connections[device_id] = []\n    platform.ws_connections[device_id].append(websocket)\n\n    try:\n        while True:\n            # Keep connection alive with ping\n            await websocket.receive_text()\n    except WebSocketDisconnect:\n        platform.ws_connections[device_id].remove(websocket)\n\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
  "variables": {
    "MQTT_BROKER": "localhost",
    "MQTT_PORT": "1883",
    "MQTT_USER": "",
    "MQTT_PASSWORD": "",
    "REDIS_URL": "redis://localhost:6379",
    "INFLUXDB_URL": "http://localhost:8086",
    "INFLUXDB_TOKEN": "",
    "INFLUXDB_ORG": "my-org",
    "INFLUXDB_BUCKET": "iot-telemetry",
    "EDGE_MODE": "false",
    "OFFLINE_STORAGE_PATH": "/var/iot/offline_data",
    "ANOMALY_THRESHOLD_SIGMA": "3.0"
  },
  "dependencies": [
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "pydantic>=2.5.0",
    "paho-mqtt>=1.6.1",
    "redis[hiredis]>=5.0.0",
    "influxdb-client>=1.38.0",
    "python-dateutil>=2.8.2"
  ],
  "workflow_context": {
    "typical_use_cases": [
      "Real-Time Telemetry Processing",
      "Edge Computing Gateway",
      "IoT Device Fleet Management",
      "Anomaly Detection in Sensor Data",
      "Offline-First IoT Applications"
    ],
    "team_composition": [
      "backend_developer",
      "devops_engineer",
      "iot_engineer"
    ],
    "estimated_time_minutes": 240,
    "prerequisites": [
      "MQTT broker (e.g., Mosquitto) running",
      "Redis server running",
      "InfluxDB 2.x installed and configured",
      "Python 3.9+ with pip",
      "Network connectivity for devices (or edge mode for offline operation)"
    ],
    "related_templates": [
      "websocket-real-time-server-v1"
    ],
    "deployment_notes": [
      "Configure MQTT broker with proper authentication",
      "Set up InfluxDB bucket and token",
      "Configure Redis for caching and pub/sub",
      "For edge deployment: Enable EDGE_MODE and configure offline storage path",
      "Use Docker Compose for easy multi-service deployment",
      "Implement MQTT TLS for production security",
      "Set up monitoring for offline queue size and sync lag",
      "Configure device heartbeat intervals based on network reliability"
    ]
  }
}
