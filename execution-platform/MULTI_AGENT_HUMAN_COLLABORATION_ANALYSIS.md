# Multi-Agent + Human Collaborative Interface
## Comprehensive Analysis & Implementation Roadmap

**Date**: October 22, 2025
**Project**: Maestro Platform (Execution-Platform + Maestro-Frontend-Production)
**Focus**: Multi-LLM + Human Discussion & Decision Interface

---

## EXECUTIVE SUMMARY

### Current State
You have **two excellent but disconnected systems**:

1. **Execution-Platform** (35% complete)
   - Provider-agnostic LLM gateway (Claude, OpenAI, Gemini)
   - FastAPI with SSE streaming
   - Persona-based routing
   - **Missing**: Multi-agent coordination, human-in-the-loop patterns

2. **Maestro-Frontend-Production** (30-40% complete)
   - Real-time multi-agent chat interface
   - 8+ AI personas with role specialization
   - WebSocket-based collaboration
   - **Missing**: Multi-LLM provider support, integrated decision workflows

### The Gap
âŒ **No unified platform where multiple LLMs (different models/providers) AND humans can simultaneously participate in discussions and reach consensus**

### Vision
âœ… A collaborative interface where:
- Multiple AI agents (Claude, GPT-4, Gemini) discuss a problem
- Humans participate in real-time
- All parties can propose solutions, debate, vote
- Decisions are documented and actionable
- Context is maintained across the discussion

---

## 1. CURRENT ARCHITECTURE ANALYSIS

### 1.1 Execution-Platform Capabilities

#### âœ… What It Does Well
```python
# Multi-provider routing
PersonaRouter.get_client("architect")  â†’ Claude
PersonaRouter.get_client("coder_openai") â†’ GPT-4
PersonaRouter.get_client("reviewer_gemini") â†’ Gemini

# Streaming responses
async for chunk in client.chat(request):
    yield chunk.delta_text

# Budget enforcement per persona
# Tool calling (2 tools: fs_read, fs_write)
```

#### âŒ What It Lacks for Multi-Agent Collaboration
1. **No Multi-Turn Orchestration**
   - Cannot coordinate conversations between multiple agents
   - No "agent A responds to agent B" pattern

2. **No Shared Context Management**
   - Each LLM call is isolated
   - No conversation threading across agents

3. **No Human-in-the-Loop Integration**
   - No mechanism for human approval/input mid-discussion
   - No voting or consensus protocols

4. **No Discussion Protocols**
   - No debate/deliberation patterns
   - No round-robin or structured discussion flows
   - No decision synthesis

---

### 1.2 Maestro-Frontend-Production Capabilities

#### âœ… What It Does Well
```typescript
// Multi-agent chat UI
<CollaborationHubMultiAgent>
  <MultiAgentChatPanel agents={[guardian, architect, coder]} />
  <TeamRoster humans={[user1, user2]} />
  <MentionSystem @agent @human />
</CollaborationHubMultiAgent>

// Real-time WebSocket
socket.on('agent:message', handleAgentMessage)
socket.on('human:message', handleHumanMessage)
socket.on('typing:indicator', showTyping)

// Decision/Approval System
<ReviewApprovalCenterEnhanced>
  <DecisionCard options={[A, B, C]} onVote={handleVote} />
  <ApprovalQueue items={pending} />
</ReviewApprovalCenterEnhanced>
```

#### âŒ What It Lacks for Multi-LLM Support
1. **Single LLM Backend**
   - Assumes one AI backend service
   - No multi-provider agent assignment

2. **No LLM-Specific Persona Mapping**
   - "Guardian AI" isn't explicitly Claude vs GPT-4
   - No provider selection UI

3. **No Cross-Provider Context**
   - Chat history not formatted for multi-LLM consumption
   - No provider-agnostic message format

---

## 2. REQUIREMENTS FOR MULTI-AGENT + HUMAN COLLABORATION

### 2.1 Core Capabilities Needed

#### A. Multi-Agent Orchestration Engine
```python
class MultiAgentOrchestrator:
    """Coordinates discussion between multiple LLMs + humans"""

    def start_discussion(
        self,
        topic: str,
        agents: List[AgentConfig],  # [Claude, GPT-4, Gemini]
        humans: List[HumanParticipant],
        discussion_protocol: DiscussionProtocol  # Round-robin, open, structured
    ) -> DiscussionSession

    def add_turn(self, participant: Agent | Human, message: str)
    def request_human_input(self, prompt: str) -> HumanResponse
    def synthesize_consensus(self) -> Decision
    def vote_on_options(self, options: List[str]) -> VoteResult
```

**Protocols Needed:**
- **Round-Robin**: Each agent gets a turn, then humans
- **Open Discussion**: Any participant can speak anytime
- **Structured Debate**: Pro/con format, then synthesis
- **Consensus Building**: Iterative refinement until agreement
- **Voting**: When agreement isn't possible

---

#### B. Shared Context Management
```python
class SharedContext:
    """Maintains conversation state across all participants"""

    discussion_id: str
    topic: str
    participants: List[Agent | Human]

    # Message history in provider-agnostic format
    messages: List[Message]  # role, content, participant_id, timestamp

    # Accumulated knowledge
    facts_established: List[str]
    proposals: List[Proposal]
    votes: Dict[str, VoteRecord]

    # Current state
    current_phase: Phase  # discussion, voting, synthesis, decided
    pending_human_input: Optional[Prompt]

    def get_context_for_agent(self, agent: Agent) -> ChatRequest:
        """Format context for specific LLM provider"""

    def add_human_message(self, human_id: str, message: str)
    def add_agent_message(self, agent_id: str, message: str)
    def mark_fact_agreed(self, fact: str)
```

---

#### C. Decision Synthesis Engine
```python
class DecisionSynthesizer:
    """Analyzes multi-agent discussion and produces actionable decisions"""

    def analyze_discussion(self, context: SharedContext) -> Analysis:
        """
        Extract:
        - Points of agreement
        - Points of disagreement
        - Proposed solutions
        - Concerns raised
        - Trade-offs identified
        """

    def identify_consensus(self, analysis: Analysis) -> Optional[Decision]:
        """Check if agents + humans have reached agreement"""

    def generate_summary(self, context: SharedContext) -> Summary:
        """Human-readable summary of discussion + decision"""

    def create_action_plan(self, decision: Decision) -> ActionPlan:
        """Convert decision into executable tasks"""
```

---

#### D. Human-in-the-Loop Integration
```typescript
interface HumanParticipant {
  userId: string
  name: string
  role: 'observer' | 'contributor' | 'decision_maker'
  permissions: {
    can_message: boolean
    can_vote: boolean
    can_veto: boolean
    must_approve: boolean  // Blocking approval required
  }
}

interface HumanInputRequest {
  type: 'approval' | 'choice' | 'feedback' | 'clarification'
  prompt: string
  options?: string[]
  deadline?: Date
  blocking: boolean  // Pause discussion until answered
}

// Frontend components needed:
<DiscussionThread
  messages={messages}
  participants={agents + humans}
  onHumanMessage={sendMessage}
/>

<DecisionPrompt
  request={humanInputRequest}
  onRespond={submitResponse}
/>

<ConsensusView
  agreements={facts}
  disagreements={conflicts}
  proposals={options}
  onVote={vote}
/>
```

---

### 2.2 Example Use Case: Architecture Decision

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Discussion: Choose Database for Apollo Project              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Participants:                                                â”‚
â”‚ ğŸ¤– Claude (Architect AI)                                    â”‚
â”‚ ğŸ¤– GPT-4 (Backend Engineer AI)                              â”‚
â”‚ ğŸ¤– Gemini (DevOps AI)                                       â”‚
â”‚ ğŸ‘¤ Alex (Product Manager) - Decision Maker                  â”‚
â”‚ ğŸ‘¤ Sarah (CTO) - Must Approve                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

TURN 1: Claude (Architect AI)
"For Apollo's requirements (high write throughput, complex
queries, multi-tenancy), I recommend PostgreSQL with
TimescaleDB extension. Benefits:
- Strong ACID guarantees
- Excellent for time-series data
- Proven at scale
- Great tooling ecosystem"

TURN 2: GPT-4 (Backend Engineer AI)
"I agree PostgreSQL is solid, but I'd like to propose
MongoDB as an alternative:
- Flexible schema for rapid iteration
- Built-in horizontal scaling
- Better for document-heavy workloads
- Our team has more MongoDB experience

Trade-off: Less mature for complex joins"

TURN 3: Gemini (DevOps AI)
"From operations perspective:
- PostgreSQL: Easier backups, better monitoring tools
- MongoDB: Simpler sharding, but more complex upgrades

Current infra: We run PostgreSQL for other projects,
so lower operational overhead to reuse expertise"

â†’ HUMAN INPUT REQUESTED â†
Alex, which factor is most important for your product roadmap?
[A] Time-to-market (favor MongoDB flexibility)
[B] Data integrity (favor PostgreSQL ACID)
[C] Team velocity (favor team experience)

TURN 4: Alex (Human - Product Manager)
"Time-to-market is critical. We need to launch in Q4.
But data integrity is also important for billing.
Can we mitigate MongoDB's ACID limitations?"

TURN 5: GPT-4 (Backend Engineer AI)
"Yes, MongoDB 4.0+ has multi-document ACID transactions.
For billing data specifically, we can:
1. Use transactions for payment operations
2. Implement idempotency keys
3. Add reconciliation jobs
This gives us speed + safety."

TURN 6: Claude (Architect AI)
"That's reasonable. I propose a hybrid approach:
- MongoDB for main application (iteration speed)
- PostgreSQL for billing/financial (ACID guarantees)
- Event-driven sync between them

Best of both worlds."

â†’ VOTE REQUESTED â†
Option A: PostgreSQL only (ACID, proven)
Option B: MongoDB only (flexible, team knows it)
Option C: Hybrid (MongoDB + PostgreSQL)

Votes:
âœ“ Claude: C (Hybrid)
âœ“ GPT-4: C (Hybrid)
âœ“ Gemini: A (PostgreSQL only - ops simplicity)
âœ“ Alex: C (Hybrid)

â†’ FINAL APPROVAL REQUIRED â†
Sarah (CTO), 3 of 4 participants favor Hybrid approach.
Gemini raised valid ops complexity concern.

[Approve Hybrid] [Override to PostgreSQL] [Request More Discussion]

TURN 7: Sarah (Human - CTO)
"Approved hybrid approach with condition:
- MongoDB must have automated backups day 1
- Billing sync must have monitoring
- 6-month review to consolidate if hybrid proves too complex

Proceed with implementation."

âœ… DECISION FINALIZED
Decision: Hybrid MongoDB + PostgreSQL
Rationale: Balances speed, safety, and team capability
Next Steps: [Action plan auto-generated]
```

---

## 3. ARCHITECTURE GAPS & NEEDED COMPONENTS

### 3.1 Missing in Execution-Platform

| Component | Current | Needed | Priority |
|-----------|---------|--------|----------|
| **Multi-Agent Coordinator** | âŒ None | Router that manages multi-LLM conversations | ğŸ”´ Critical |
| **Discussion Protocol Engine** | âŒ None | Round-robin, debate, consensus protocols | ğŸ”´ Critical |
| **Shared Context Store** | âŒ None | Redis/DB for cross-agent conversation state | ğŸ”´ Critical |
| **Human Input Queue** | âŒ None | Pause execution, wait for human response | ğŸ”´ Critical |
| **Decision Synthesizer** | âŒ None | Analyze discussion, extract decisions | ğŸŸ  High |
| **Consensus Algorithm** | âŒ None | Voting, agreement detection | ğŸŸ  High |
| **Artifact Linking** | âŒ None | Connect decisions to artifacts/tasks | ğŸŸ¡ Medium |

### 3.2 Missing in Maestro-Frontend-Production

| Component | Current | Needed | Priority |
|-----------|---------|--------|----------|
| **Multi-Provider Agent Assignment** | âŒ Single backend | UI to assign agent â†’ LLM provider | ğŸ”´ Critical |
| **Discussion View** | âš ï¸ Basic chat | Structured discussion interface | ğŸ”´ Critical |
| **Consensus UI** | âŒ None | Show agreements/disagreements/votes | ğŸ”´ Critical |
| **Human Input Prompts** | âš ï¸ Approval only | Blocking prompts in discussion flow | ğŸŸ  High |
| **Decision Summary View** | âŒ None | Render final decision with rationale | ğŸŸ  High |
| **Participant Status** | âš ï¸ Basic | Show which agent is "thinking" | ğŸŸ¡ Medium |

---

## 4. OPEN-SOURCE SOLUTIONS COMPARISON

### 4.1 Multi-Agent Frameworks

#### Option 1: **AutoGen** (Microsoft) â­ Recommended
```python
# Pros:
+ Open source (MIT license)
+ Multi-agent conversation patterns built-in
+ Human-in-the-loop support
+ Supports multiple LLM providers
+ Active community (10K+ GitHub stars)
+ Production-ready

# Example:
from autogen import AssistantAgent, UserProxyAgent

assistant = AssistantAgent("architect", llm_config={"model": "claude-3"})
coder = AssistantAgent("coder", llm_config={"model": "gpt-4"})
reviewer = AssistantAgent("reviewer", llm_config={"model": "gemini-pro"})
human = UserProxyAgent("product_manager", human_input_mode="ALWAYS")

groupchat = autogen.GroupChat(
    agents=[assistant, coder, reviewer, human],
    messages=[],
    max_round=10
)
manager = autogen.GroupChatManager(groupchat=groupchat)
human.initiate_chat(manager, message="Design database for Apollo")
```

**Integration Effort:** 2-3 weeks
**Fit:** Excellent - designed for this exact use case

---

#### Option 2: **CrewAI**
```python
# Pros:
+ Role-based agent collaboration
+ Task delegation patterns
+ Simpler than AutoGen
+ Good documentation

# Cons:
- Less flexible for custom protocols
- Smaller community
- Fewer multi-provider examples

from crewai import Agent, Task, Crew

architect = Agent(role="Architect", llm="claude-3")
engineer = Agent(role="Engineer", llm="gpt-4")
devops = Agent(role="DevOps", llm="gemini-pro")

task = Task(description="Choose database", agents=[architect, engineer, devops])
crew = Crew(agents=[architect, engineer, devops], tasks=[task])
result = crew.kickoff()
```

**Integration Effort:** 1-2 weeks
**Fit:** Good for simpler workflows

---

#### Option 3: **LangGraph** (LangChain)
```python
# Pros:
+ Graph-based agent orchestration
+ Excellent for complex workflows
+ Built on LangChain ecosystem
+ Human-in-the-loop nodes

# Cons:
- Steeper learning curve
- More focused on workflows than discussions
- Overkill for simple collaborations

from langgraph import StateGraph, END

def architect_node(state):
    response = architect_llm.invoke(state["messages"])
    return {"messages": state["messages"] + [response]}

workflow = StateGraph()
workflow.add_node("architect", architect_node)
workflow.add_node("human_approval", human_approval_node)
workflow.add_edge("architect", "human_approval")
```

**Integration Effort:** 3-4 weeks
**Fit:** Better for workflow automation than discussion

---

#### Option 4: **Build Custom on Execution-Platform**
```python
# Pros:
+ Full control
+ No external dependencies
+ Optimized for your exact needs

# Cons:
- 6-8 weeks development time
- Need to implement protocols yourself
- Reinventing the wheel

class CustomMultiAgentOrchestrator:
    def __init__(self, execution_platform_router):
        self.router = execution_platform_router
        self.context = SharedContext()

    def run_discussion(self, agents, humans, topic):
        # Implement round-robin, voting, consensus, etc.
        pass
```

**Integration Effort:** 6-8 weeks
**Fit:** Maximum flexibility, but expensive

---

### 4.2 Chat/Collaboration Platforms

#### Option 1: **Lobe Chat** â­ For UI inspiration
- Open-source multi-model chat UI
- Beautiful UX, mobile-optimized
- Plugin marketplace
- Can fork and customize

**Use:** Frontend reference, not direct integration

#### Option 2: **Chatwoot**
- Open-source customer messaging platform
- Multi-agent support
- WebSocket real-time
- Not designed for AI agents

**Use:** Could adapt for human-human collaboration

---

### 4.3 Decision Support Systems

#### Option 1: **Polis** (Computational Democracy)
- Open-source opinion clustering
- Voting and consensus algorithms
- Visualization of agreement/disagreement
- Used by governments for public consultation

**Use:** Inspiration for consensus visualization

#### Option 2: **All Our Ideas**
- Collaborative idea generation
- Pairwise comparison voting
- Princeton research project

**Use:** Voting UI patterns

---

## 5. RECOMMENDED ARCHITECTURE

### 5.1 Hybrid Approach: AutoGen + Custom Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Maestro Frontend                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ <DiscussionInterface>                                  â”‚  â”‚
â”‚  â”‚   - Multi-agent chat UI                                â”‚  â”‚
â”‚  â”‚   - Human input prompts                                â”‚  â”‚
â”‚  â”‚   - Consensus visualization                            â”‚  â”‚
â”‚  â”‚   - Decision cards                                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â†“ WebSocket + REST                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Discussion Orchestrator Service (NEW)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Built with AutoGen + Custom Logic                      â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚ - Multi-agent conversation management                  â”‚  â”‚
â”‚  â”‚ - Discussion protocol engine                           â”‚  â”‚
â”‚  â”‚ - Human-in-the-loop queue                             â”‚  â”‚
â”‚  â”‚ - Consensus detection                                  â”‚  â”‚
â”‚  â”‚ - Decision synthesis                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â†“ Uses                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  Execution Platform Gateway                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ PersonaRouter                                          â”‚  â”‚
â”‚  â”‚   - Claude: Architect, QA                              â”‚  â”‚
â”‚  â”‚   - GPT-4: Backend Eng, Frontend Eng                  â”‚  â”‚
â”‚  â”‚   - Gemini: DevOps, Security                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â†“                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               Provider APIs (Claude, OpenAI, Gemini)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 New Component: Discussion Orchestrator Service

**Tech Stack:**
- Python (for AutoGen compatibility)
- FastAPI (REST + WebSocket)
- Redis (shared context storage)
- PostgreSQL (discussion persistence)

**Responsibilities:**
1. **Initiate Discussions**
   ```python
   POST /v1/discussions
   {
     "topic": "Choose database for Apollo",
     "agents": [
       {"persona": "architect", "provider": "claude"},
       {"persona": "backend_eng", "provider": "openai"},
       {"persona": "devops", "provider": "gemini"}
     ],
     "humans": [
       {"user_id": "alex", "role": "decision_maker"},
       {"user_id": "sarah", "role": "must_approve"}
     ],
     "protocol": "structured_debate"
   }
   â†’ Returns discussion_id
   ```

2. **Stream Discussion Events**
   ```python
   WebSocket /v1/discussions/{id}/stream

   Events:
   - agent:thinking {agent_id}
   - agent:message {agent_id, message}
   - human:input_required {prompt, options}
   - consensus:detected {agreements, disagreements}
   - decision:finalized {decision, rationale, action_plan}
   ```

3. **Handle Human Input**
   ```python
   POST /v1/discussions/{id}/human-input
   {
     "user_id": "alex",
     "response": "Time-to-market is most critical",
     "type": "choice" | "approval" | "message"
   }
   ```

4. **Synthesize Decisions**
   ```python
   GET /v1/discussions/{id}/decision

   {
     "status": "decided" | "in_progress" | "deadlocked",
     "decision": "Hybrid MongoDB + PostgreSQL",
     "rationale": "Balances speed, safety, team capability",
     "supporting_votes": 3,
     "dissenting_votes": 1,
     "action_plan": [
       "Set up MongoDB cluster",
       "Configure PostgreSQL for billing",
       "Implement event sync"
     ]
   }
   ```

---

## 6. IMPLEMENTATION ROADMAP

### Phase 0: Foundation (Week 1-2) ğŸ—ï¸

**Goal:** Set up Discussion Orchestrator service

**Tasks:**
1. Create new Python service (`discussion-orchestrator/`)
2. Install AutoGen: `pip install pyautogen`
3. Integrate with Execution Platform:
   ```python
   from execution_platform.router import PersonaRouter

   router = PersonaRouter()
   architect_llm = router.get_client("architect")  # Claude
   ```
4. Set up Redis for shared context
5. Create basic FastAPI endpoints
6. Deploy alongside Execution Platform

**Deliverables:**
- âœ… New service running on port 5000
- âœ… Can create discussions
- âœ… Integrated with Execution Platform

**Time:** 1-2 weeks, 1 engineer

---

### Phase 1: Multi-Agent Discussion (Week 3-5) ğŸ’¬

**Goal:** Multi-LLM agents can discuss topics

**Tasks:**
1. **Implement AutoGen Integration**
   ```python
   class DiscussionManager:
       def create_agents(self, agent_configs):
           agents = []
           for config in agent_configs:
               llm_client = self.router.get_client(config.persona)
               agent = AssistantAgent(
                   name=config.name,
                   llm_client=llm_client,
                   system_message=config.system_prompt
               )
               agents.append(agent)
           return agents

       def run_discussion(self, topic, agents, protocol):
           if protocol == "round_robin":
               return self.run_round_robin(topic, agents)
           elif protocol == "open":
               return self.run_open_discussion(topic, agents)
   ```

2. **Implement Discussion Protocols**
   - Round-robin: Each agent gets one turn
   - Open discussion: Agents can respond to each other
   - Structured debate: Pro/con, then synthesis

3. **Shared Context Storage**
   ```python
   class SharedContext:
       def __init__(self, discussion_id):
           self.redis_key = f"discussion:{discussion_id}"

       def add_message(self, participant, message):
           self.redis.rpush(self.redis_key, json.dumps({
               "participant": participant,
               "message": message,
               "timestamp": time.time()
           }))

       def get_history(self):
           return [json.loads(m) for m in self.redis.lrange(self.redis_key, 0, -1)]
   ```

4. **WebSocket Streaming**
   - Stream agent messages in real-time
   - Emit typing indicators

**Deliverables:**
- âœ… Multi-agent discussions work
- âœ… 3 discussion protocols implemented
- âœ… WebSocket streaming functional

**Time:** 3 weeks, 1-2 engineers

---

### Phase 2: Human-in-the-Loop (Week 6-7) ğŸ‘¤

**Goal:** Humans can participate in discussions

**Tasks:**
1. **Human Input Queue**
   ```python
   class HumanInputQueue:
       def request_input(self, discussion_id, prompt, options, blocking=True):
           request = {
               "prompt": prompt,
               "options": options,
               "blocking": blocking,
               "requested_at": time.time()
           }
           self.redis.set(f"human_input:{discussion_id}", json.dumps(request))

           if blocking:
               # Pause discussion until response received
               self.pause_discussion(discussion_id)

           # Emit WebSocket event to frontend
           self.socket.emit("human_input_required", request)

       async def wait_for_response(self, discussion_id, timeout=300):
           # Poll Redis for response
           for _ in range(timeout):
               response = self.redis.get(f"human_response:{discussion_id}")
               if response:
                   return json.loads(response)
               await asyncio.sleep(1)
           raise TimeoutError("Human didn't respond in time")
   ```

2. **Frontend Human Input Components**
   ```typescript
   <HumanInputPrompt
     prompt="Which factor is most important?"
     options={["Time-to-market", "Data integrity", "Team velocity"]}
     onRespond={(choice) => {
       api.post(`/discussions/${id}/human-input`, {
         response: choice,
         type: "choice"
       })
     }}
   />
   ```

3. **Approval Workflows**
   - Blocking approvals (discussion paused)
   - Non-blocking feedback
   - Veto authority for certain humans

**Deliverables:**
- âœ… Humans can respond to prompts
- âœ… Discussions pause for blocking inputs
- âœ… Approval workflows integrated

**Time:** 2 weeks, 1-2 engineers

---

### Phase 3: Consensus & Decisions (Week 8-9) âœ…

**Goal:** Synthesize decisions from discussions

**Tasks:**
1. **Voting System**
   ```python
   class VotingSystem:
       def initiate_vote(self, discussion_id, options):
           vote_record = {
               "options": options,
               "votes": {},
               "started_at": time.time()
           }
           self.redis.set(f"vote:{discussion_id}", json.dumps(vote_record))

       def cast_vote(self, discussion_id, participant_id, choice):
           vote_record = self.get_vote_record(discussion_id)
           vote_record["votes"][participant_id] = choice
           self.redis.set(f"vote:{discussion_id}", json.dumps(vote_record))

       def tally_votes(self, discussion_id):
           vote_record = self.get_vote_record(discussion_id)
           counts = {}
           for choice in vote_record["votes"].values():
               counts[choice] = counts.get(choice, 0) + 1
           return counts
   ```

2. **Consensus Detection**
   ```python
   class ConsensusDetector:
       def analyze_discussion(self, context):
           # Use Claude to analyze discussion
           analysis_prompt = f"""
           Analyze this discussion and identify:
           1. Points everyone agrees on
           2. Points of disagreement
           3. Proposed solutions
           4. Whether consensus has been reached

           Discussion:
           {context.get_history()}
           """

           analyzer_llm = self.router.get_client("consensus_analyzer")
           analysis = analyzer_llm.chat(ChatRequest(
               messages=[Message(role="user", content=analysis_prompt)]
           ))

           return self.parse_analysis(analysis)

       def has_consensus(self, analysis):
           # Check if >75% agreement on key points
           return analysis.agreement_percentage > 0.75
   ```

3. **Decision Synthesis**
   ```python
   class DecisionSynthesizer:
       def synthesize_decision(self, discussion_id):
           context = self.get_context(discussion_id)

           synthesis_prompt = f"""
           Based on this multi-agent discussion, create:
           1. Final decision (1-2 sentences)
           2. Rationale (why this decision)
           3. Action plan (3-5 concrete next steps)

           Discussion:
           {context.get_history()}

           Voting results:
           {self.voting.tally_votes(discussion_id)}
           """

           synthesizer_llm = self.router.get_client("decision_synthesizer")
           decision = synthesizer_llm.chat(ChatRequest(
               messages=[Message(role="user", content=synthesis_prompt)]
           ))

           return self.format_decision(decision)
   ```

**Deliverables:**
- âœ… Voting system functional
- âœ… Consensus detection works
- âœ… Decisions auto-generated

**Time:** 2 weeks, 1-2 engineers

---

### Phase 4: Frontend Integration (Week 10-11) ğŸ¨

**Goal:** Rich UI for multi-agent discussions

**Tasks:**
1. **Discussion View Component**
   ```typescript
   <DiscussionView discussionId={id}>
     <ParticipantList
       agents={[
         {name: "Claude (Architect)", status: "thinking"},
         {name: "GPT-4 (Engineer)", status: "idle"},
         {name: "Gemini (DevOps)", status: "typing"}
       ]}
       humans={[
         {name: "Alex (PM)", status: "active"},
         {name: "Sarah (CTO)", status: "away"}
       ]}
     />

     <MessageThread messages={messages}>
       {messages.map(m => (
         <Message
           participant={m.participant}
           content={m.content}
           timestamp={m.timestamp}
           isAgent={m.type === "agent"}
         />
       ))}
     </MessageThread>

     <ConsensusPanel
       agreements={["PostgreSQL is solid", "MongoDB is flexible"]}
       disagreements={["Operational complexity"]}
       proposals={["Hybrid approach", "PostgreSQL only"]}
     />

     {humanInputRequired && (
       <HumanInputPrompt {...humanInputRequest} />
     )}
   </DiscussionView>
   ```

2. **Real-time Updates**
   ```typescript
   useEffect(() => {
     const ws = io(`ws://localhost:5000/discussions/${id}/stream`)

     ws.on('agent:thinking', (data) => {
       setParticipantStatus(data.agent_id, 'thinking')
     })

     ws.on('agent:message', (data) => {
       addMessage({
         participant: data.agent_id,
         content: data.message,
         type: 'agent'
       })
     })

     ws.on('human:input_required', (data) => {
       setHumanInputRequired(data)
     })

     ws.on('decision:finalized', (data) => {
       setDecision(data.decision)
       setDiscussionStatus('completed')
     })
   }, [id])
   ```

3. **Decision Summary View**
   ```typescript
   <DecisionSummary decision={finalDecision}>
     <DecisionCard>
       <h2>{decision.title}</h2>
       <p>{decision.description}</p>

       <RationaleSection>
         <h3>Why this decision?</h3>
         <p>{decision.rationale}</p>
       </RationaleSection>

       <VoteBreakdown votes={decision.votes} />

       <ActionPlan steps={decision.action_plan} />

       <ParticipantSignoffs
         agents={decision.supporting_agents}
         humans={decision.approvers}
       />
     </DecisionCard>
   </DecisionSummary>
   ```

**Deliverables:**
- âœ… Full discussion UI
- âœ… Real-time updates working
- âœ… Decision visualization

**Time:** 2 weeks, 1-2 frontend engineers

---

### Phase 5: Advanced Features (Week 12-14) ğŸš€

**Optional enhancements:**

1. **Discussion Templates**
   - Architecture decision template
   - Technical spike template
   - Design review template

2. **Agent Personality Tuning**
   - Adjust how assertive/collaborative each agent is
   - Configure when agents defer to humans

3. **Discussion Analytics**
   - Time to decision metrics
   - Consensus quality scores
   - Participant engagement analytics

4. **Multi-Discussion Coordination**
   - Spawn sub-discussions from main thread
   - Cross-reference related discussions
   - Decision dependency tracking

**Time:** 3 weeks, 1-2 engineers

---

## 7. EFFORT ESTIMATION

### Summary

| Phase | Duration | Engineers | Focus |
|-------|----------|-----------|-------|
| Phase 0: Foundation | 1-2 weeks | 1 backend | New service setup |
| Phase 1: Multi-Agent | 3 weeks | 1-2 backend | AutoGen integration |
| Phase 2: Human-in-Loop | 2 weeks | 1-2 backend | Human input queue |
| Phase 3: Consensus | 2 weeks | 1-2 backend | Voting, synthesis |
| Phase 4: Frontend | 2 weeks | 1-2 frontend | UI components |
| Phase 5: Advanced | 3 weeks | 1-2 full-stack | Optional enhancements |
| **Total** | **13-14 weeks** | **2-3 FTE** | **MVP** |

### Minimum Viable Product (MVP)
**Timeline:** 10 weeks
**Scope:** Phase 0-4 (skip advanced features)
**Team:** 2 engineers (1 backend, 1 frontend)

**MVP Features:**
âœ… Multi-LLM discussions (Claude, GPT-4, Gemini)
âœ… Human participation with input prompts
âœ… Voting and consensus detection
âœ… Decision synthesis and action plans
âœ… Real-time UI with WebSocket updates

---

## 8. TECHNOLOGY RECOMMENDATIONS

### Core Stack

**Discussion Orchestrator Service:**
- **Language:** Python 3.11+
- **Framework:** FastAPI (REST + WebSocket)
- **Multi-Agent:** AutoGen
- **State:** Redis (shared context)
- **Persistence:** PostgreSQL (discussion history)
- **Deployment:** Docker + Docker Compose

**Frontend Enhancements:**
- **UI Library:** Continue using React 18 + TypeScript
- **State:** Zustand (for discussion state)
- **WebSocket:** Socket.IO client (already in use)
- **New Components:** Discussion view, consensus panel, decision cards

**Integration:**
- **LLM Gateway:** Use existing Execution Platform
- **Authentication:** Reuse Maestro frontend auth
- **Storage:** Share PostgreSQL with Maestro backend

---

## 9. ALTERNATIVE: OPEN-SOURCE PLATFORMS

If you prefer a ready-made solution instead of building custom:

### Option A: **Rasa + Custom UI** (Conversational AI)
**Effort:** 4-6 weeks
**Pros:** Strong NLU, multi-agent support, open-source
**Cons:** Designed for chatbots, not multi-LLM collaboration

### Option B: **Botpress** (Agent Platform)
**Effort:** 3-4 weeks
**Pros:** Visual flow builder, multi-agent workflows
**Cons:** Less flexible for custom discussion protocols

### Option C: **Haystack + Streamlit** (LLM Pipelines + UI)
**Effort:** 6-8 weeks
**Pros:** Excellent for multi-LLM pipelines, Streamlit for quick UI
**Cons:** Requires significant customization for collaboration

### Option D: **Fork Lobe Chat** (Multi-Model Chat UI)
**Effort:** 4-5 weeks
**Pros:** Beautiful UI, multi-model support, open-source (MIT)
**Cons:** Designed for single-user, needs collaboration features added

**Recommendation:** None of these are perfect fits. Building custom with AutoGen is best approach.

---

## 10. RISKS & MITIGATIONS

### Risk 1: AutoGen Learning Curve
**Probability:** Medium
**Impact:** 2-3 week delay
**Mitigation:**
- Start with AutoGen tutorials (1 week)
- Build simple proof-of-concept first
- Have fallback: implement basic multi-agent without AutoGen

### Risk 2: Execution Platform Not Stable
**Probability:** Medium (35% complete)
**Impact:** Blocks integration
**Mitigation:**
- Complete Execution Platform Phase 0.5 (provider validation) first
- Run parallel development where possible
- Have mock LLM clients for testing

### Risk 3: WebSocket Complexity
**Probability:** Low
**Impact:** 1 week delay
**Mitigation:**
- Maestro frontend already uses WebSocket
- Reuse existing patterns
- Use Socket.IO library (battle-tested)

### Risk 4: Consensus Algorithm Difficulty
**Probability:** Medium
**Impact:** 1-2 week delay
**Mitigation:**
- Start with simple voting (>50% majority)
- Use Claude to analyze discussion for consensus
- Add sophisticated algorithms later (Phase 5)

---

## 11. SUCCESS METRICS

### Phase 0-1 Success (Multi-Agent Discussion)
- âœ… 3+ LLMs can have a conversation
- âœ… Discussion history is preserved
- âœ… Real-time streaming works
- âœ… Latency <2s per agent response

### Phase 2 Success (Human-in-Loop)
- âœ… Humans can respond to prompts in <30s
- âœ… Discussions pause correctly for blocking inputs
- âœ… No message loss in WebSocket

### Phase 3-4 Success (Decisions)
- âœ… Consensus detected correctly (>80% accuracy)
- âœ… Decisions are actionable and clear
- âœ… Users can understand discussion flow
- âœ… Time-to-decision <10 minutes

### Production Success (3 months post-launch)
- ğŸ“Š 50+ discussions completed
- ğŸ“Š >75% user satisfaction
- ğŸ“Š Average time-to-decision <8 minutes
- ğŸ“Š >90% decisions implemented successfully

---

## 12. NEXT IMMEDIATE ACTIONS

### This Week
1. **[ ] Decide on approach:**
   - Build custom with AutoGen (recommended)
   - OR adopt existing platform

2. **[ ] Assign team:**
   - 1 backend engineer (Python, AutoGen)
   - 1 frontend engineer (React, WebSocket)

3. **[ ] Set up Discussion Orchestrator repo:**
   ```bash
   mkdir discussion-orchestrator
   cd discussion-orchestrator
   python -m venv venv
   pip install fastapi uvicorn pyautogen redis
   ```

4. **[ ] Complete Execution Platform Phase 0.5:**
   - Validate OpenAI adapter
   - Validate Gemini adapter
   - Obtain Anthropic API key

### Next Week
1. **[ ] Build Phase 0:**
   - Basic FastAPI service
   - Integrate with Execution Platform
   - Test multi-provider routing

2. **[ ] Create proof-of-concept:**
   - 2 agents (Claude + GPT-4) discuss a topic
   - Stream responses to console
   - Validate AutoGen integration

---

## 13. CONCLUSION

### Current State
ğŸŸ¡ **You have the pieces, but they're not connected:**
- Execution Platform: Multi-provider LLM routing âœ…
- Maestro Frontend: Multi-agent chat UI âœ…
- **Missing**: Orchestration layer to connect them

### Recommended Path
ğŸ¯ **Build Discussion Orchestrator with AutoGen:**
- 10-14 weeks to MVP
- 2-3 engineers
- Best fit for your architecture
- Open-source (AutoGen) + custom glue

### Alternative Path
ğŸ”„ **Adopt existing platform:**
- 4-6 weeks integration
- Less flexibility
- No perfect fit exists

### Decision Framework
Choose **Build Custom** if:
- âœ… You have 2-3 engineers available
- âœ… You need maximum flexibility
- âœ… 10-14 weeks is acceptable

Choose **Adopt Platform** if:
- âœ… You need solution in <6 weeks
- âœ… You're OK with less customization
- âœ… You have limited engineering bandwidth

### Final Recommendation
ğŸš€ **Build custom with AutoGen** - it's the right long-term investment for your platform.

---

## Appendix A: Code Samples

### A.1 Minimal Discussion Orchestrator

```python
# discussion_orchestrator/main.py
from fastapi import FastAPI, WebSocket
from autogen import AssistantAgent, GroupChat, GroupChatManager
import sys
sys.path.append("../execution-platform")
from execution_platform.router import PersonaRouter

app = FastAPI()
router = PersonaRouter()

@app.post("/v1/discussions")
async def create_discussion(request: DiscussionRequest):
    # Create agents for each LLM provider
    agents = []
    for agent_config in request.agents:
        llm_client = router.get_client(agent_config.persona)
        agent = AssistantAgent(
            name=agent_config.name,
            llm_client=llm_client,
            system_message=agent_config.system_prompt
        )
        agents.append(agent)

    # Start group chat
    groupchat = GroupChat(agents=agents, messages=[], max_round=10)
    manager = GroupChatManager(groupchat=groupchat)

    # Store discussion in Redis
    discussion_id = str(uuid.uuid4())
    redis.set(f"discussion:{discussion_id}", json.dumps({
        "agents": [a.name for a in agents],
        "status": "active",
        "created_at": time.time()
    }))

    return {"discussion_id": discussion_id}

@app.websocket("/v1/discussions/{discussion_id}/stream")
async def stream_discussion(websocket: WebSocket, discussion_id: str):
    await websocket.accept()

    # Get discussion from Redis
    discussion = json.loads(redis.get(f"discussion:{discussion_id}"))

    # Stream messages as they're generated
    async for message in manager.get_messages():
        await websocket.send_json({
            "type": "agent:message",
            "agent": message.agent,
            "content": message.content
        })
```

### A.2 Frontend Discussion Component

```typescript
// frontend/src/components/DiscussionView.tsx
import React, { useState, useEffect } from 'react'
import { io } from 'socket.io-client'

export const DiscussionView: React.FC<{discussionId: string}> = ({discussionId}) => {
  const [messages, setMessages] = useState<Message[]>([])
  const [participants, setParticipants] = useState<Participant[]>([])

  useEffect(() => {
    const ws = io(`http://localhost:5000/discussions/${discussionId}/stream`)

    ws.on('agent:message', (data) => {
      setMessages(prev => [...prev, {
        type: 'agent',
        participant: data.agent,
        content: data.content,
        timestamp: Date.now()
      }])
    })

    ws.on('human:input_required', (data) => {
      setHumanInputRequest(data)
    })

    return () => ws.disconnect()
  }, [discussionId])

  return (
    <div className="discussion-view">
      <ParticipantList participants={participants} />
      <MessageThread messages={messages} />
      {humanInputRequest && (
        <HumanInputPrompt request={humanInputRequest} />
      )}
    </div>
  )
}
```

---

**Document Version:** 1.0
**Last Updated:** October 22, 2025
**Next Review:** After Phase 0 completion
**Owner:** Technical Architecture Team

---

[END OF ANALYSIS]
