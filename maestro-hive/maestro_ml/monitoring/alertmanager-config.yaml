# AlertManager Configuration for Maestro ML Platform
#
# Deploy with:
#   kubectl create configmap alertmanager-config --from-file=alertmanager.yml
#   kubectl apply -f alertmanager-deployment.yaml

global:
  # Global configuration
  resolve_timeout: 5m
  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

# ============================================================================
# Templates
# ============================================================================
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# ============================================================================
# Routing Tree
# ============================================================================
route:
  # Default receiver for unmatched alerts
  receiver: 'default'

  # Group alerts by these labels to reduce noise
  group_by: ['alertname', 'cluster', 'service']

  # How long to wait before sending first notification for a group
  group_wait: 30s

  # How long to wait before sending notification about new alerts in an existing group
  group_interval: 5m

  # How long to wait before resending a notification
  repeat_interval: 4h

  # Child routes
  routes:
    # ========================================================================
    # Critical Alerts -> PagerDuty
    # ========================================================================
    - match:
        severity: critical
      receiver: 'pagerduty'
      continue: true  # Also send to other routes
      group_wait: 10s
      group_interval: 1m
      repeat_interval: 1h

    # ========================================================================
    # SLO Violations -> PagerDuty + Slack
    # ========================================================================
    - match:
        category: slo
      receiver: 'slo-team'
      group_wait: 1m
      group_interval: 5m
      repeat_interval: 2h

    # ========================================================================
    # Security Alerts -> Security Team
    # ========================================================================
    - match:
        category: security
      receiver: 'security-team'
      group_wait: 30s
      group_interval: 2m
      repeat_interval: 30m

    # ========================================================================
    # Database Alerts -> Database Team
    # ========================================================================
    - match:
        category: database
      receiver: 'database-team'
      group_wait: 1m
      group_interval: 5m
      repeat_interval: 1h

    # ========================================================================
    # Performance Alerts -> Performance Team (Slack)
    # ========================================================================
    - match:
        category: performance
      receiver: 'performance-team'
      group_wait: 2m
      group_interval: 10m
      repeat_interval: 4h

    # ========================================================================
    # Business Metrics -> Business Team (Email)
    # ========================================================================
    - match:
        category: business
      receiver: 'business-team'
      group_wait: 5m
      group_interval: 15m
      repeat_interval: 12h

    # ========================================================================
    # Warning Alerts -> Slack
    # ========================================================================
    - match:
        severity: warning
      receiver: 'slack-warnings'
      group_wait: 2m
      group_interval: 10m
      repeat_interval: 6h

    # ========================================================================
    # Info Alerts -> Email
    # ========================================================================
    - match:
        severity: info
      receiver: 'email-info'
      group_wait: 5m
      group_interval: 30m
      repeat_interval: 24h

# ============================================================================
# Inhibition Rules (Suppress alerts based on other alerts)
# ============================================================================
inhibit_rules:
  # Inhibit warning if critical alert is firing
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'service']

  # Inhibit individual alerts if service is down
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '.*'
    equal: ['service']

  # Inhibit low error budget if SLO is already violated
  - source_match:
      alertname: 'SLOViolation'
    target_match:
      alertname: 'ErrorBudgetLow'
    equal: ['service']

# ============================================================================
# Receivers
# ============================================================================
receivers:
  # ==========================================================================
  # Default Receiver
  # ==========================================================================
  - name: 'default'
    slack_configs:
      - channel: '#alerts-general'
        title: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Service:* {{ .Labels.service }}
          {{ end }}

  # ==========================================================================
  # PagerDuty (Critical Alerts)
  # ==========================================================================
  - name: 'pagerduty'
    pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
        description: '{{ .GroupLabels.alertname }}: {{ .Annotations.summary }}'
        client: 'Maestro ML AlertManager'
        client_url: '{{ template "pagerduty.default.client_url" . }}'
        details:
          summary: '{{ .Annotations.summary }}'
          description: '{{ .Annotations.description }}'
          severity: '{{ .GroupLabels.severity }}'
          runbook: '{{ .Annotations.runbook }}'

  # ==========================================================================
  # SLO Team (PagerDuty + Slack)
  # ==========================================================================
  - name: 'slo-team'
    pagerduty_configs:
      - service_key: 'YOUR_SLO_PAGERDUTY_KEY'
        description: 'SLO Violation: {{ .Annotations.summary }}'

    slack_configs:
      - channel: '#slo-alerts'
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
        title: '[SLO {{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        text: |
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}

          *Details:*
          {{ range .Alerts }}
          • Service: {{ .Labels.service }}
          • Current SLI: {{ .Labels.current_sli }}
          • Target: {{ .Labels.slo_target }}
          {{ end }}

          <{{ .Annotations.runbook }}|Runbook>

  # ==========================================================================
  # Security Team
  # ==========================================================================
  - name: 'security-team'
    slack_configs:
      - channel: '#security-alerts'
        color: 'danger'
        title: '[SECURITY {{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        text: |
          *⚠️ SECURITY ALERT ⚠️*

          {{ .Annotations.summary }}

          {{ range .Alerts }}
          *Details:*
          {{ .Annotations.description }}

          *Affected Service:* {{ .Labels.service }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}

          <{{ .Annotations.runbook }}|Response Runbook>

    email_configs:
      - to: 'security@company.com'
        from: 'alertmanager@company.com'
        smarthost: 'smtp.company.com:587'
        auth_username: 'alerts@company.com'
        auth_password: 'YOUR_EMAIL_PASSWORD'
        headers:
          Subject: '[SECURITY] {{ .GroupLabels.alertname }}'
        html: |
          <h2>Security Alert</h2>
          <p><strong>{{ .Annotations.summary }}</strong></p>
          {{ range .Alerts }}
          <p>{{ .Annotations.description }}</p>
          <ul>
            <li>Service: {{ .Labels.service }}</li>
            <li>Severity: {{ .Labels.severity }}</li>
            <li>Time: {{ .StartsAt }}</li>
          </ul>
          {{ end }}

  # ==========================================================================
  # Database Team
  # ==========================================================================
  - name: 'database-team'
    slack_configs:
      - channel: '#database-alerts'
        title: '[DB {{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Summary:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}

  # ==========================================================================
  # Performance Team
  # ==========================================================================
  - name: 'performance-team'
    slack_configs:
      - channel: '#performance-alerts'
        title: '[PERF {{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          {{ end }}

  # ==========================================================================
  # Business Team
  # ==========================================================================
  - name: 'business-team'
    email_configs:
      - to: 'business-team@company.com'
        from: 'alertmanager@company.com'
        smarthost: 'smtp.company.com:587'
        auth_username: 'alerts@company.com'
        auth_password: 'YOUR_EMAIL_PASSWORD'
        headers:
          Subject: '[Business Metrics] {{ .GroupLabels.alertname }}'
        html: |
          <h2>Business Metrics Alert</h2>
          {{ range .Alerts }}
          <p><strong>{{ .Annotations.summary }}</strong></p>
          <p>{{ .Annotations.description }}</p>
          {{ end }}

  # ==========================================================================
  # Slack Warnings
  # ==========================================================================
  - name: 'slack-warnings'
    slack_configs:
      - channel: '#warnings'
        color: 'warning'
        title: '[WARNING] {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          {{ .Annotations.summary }}
          {{ end }}

  # ==========================================================================
  # Email Info
  # ==========================================================================
  - name: 'email-info'
    email_configs:
      - to: 'ops-team@company.com'
        from: 'alertmanager@company.com'
        smarthost: 'smtp.company.com:587'
        auth_username: 'alerts@company.com'
        auth_password: 'YOUR_EMAIL_PASSWORD'
        headers:
          Subject: '[Info] {{ .GroupLabels.alertname }}'
        html: |
          <h3>Informational Alert</h3>
          {{ range .Alerts }}
          <p>{{ .Annotations.summary }}</p>
          {{ end }}

# ============================================================================
# Notification Templates
# ============================================================================
#
# Create file: /etc/alertmanager/templates/default.tmpl
#
# {{ define "slack.default.title" }}
# [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}]
# {{ .GroupLabels.alertname }}
# {{ end }}
#
# {{ define "slack.default.text" }}
# {{ range .Alerts }}
# *Summary:* {{ .Annotations.summary }}
# *Description:* {{ .Annotations.description }}
# *Severity:* {{ .Labels.severity }}
# *Started:* {{ .StartsAt.Format "2006-01-02 15:04:05 MST" }}
# {{ if .Annotations.runbook }}
# *Runbook:* {{ .Annotations.runbook }}
# {{ end }}
# {{ end }}
# {{ end }}
#
# ============================================================================

# ============================================================================
# Deployment Instructions
# ============================================================================
#
# 1. Create ConfigMap:
#    kubectl create configmap alertmanager-config \
#      --from-file=alertmanager.yml=alertmanager-config.yaml \
#      -n monitoring
#
# 2. Create Secret for sensitive data:
#    kubectl create secret generic alertmanager-secrets \
#      --from-literal=slack-webhook-url='https://hooks.slack.com/...' \
#      --from-literal=pagerduty-key='YOUR_KEY' \
#      --from-literal=email-password='YOUR_PASSWORD' \
#      -n monitoring
#
# 3. Deploy AlertManager:
#    kubectl apply -f alertmanager-deployment.yaml
#
# 4. Verify:
#    kubectl logs -f deployment/alertmanager -n monitoring
#
# 5. Test:
#    # Send test alert
#    curl -X POST http://alertmanager:9093/api/v1/alerts \
#      -d '[{
#        "labels": {"alertname":"TestAlert","severity":"warning"},
#        "annotations": {"summary":"Test alert"}
#      }]'
#
# ============================================================================
# Configuration Reference
# ============================================================================
#
# Severity Levels:
#   - critical:  Page on-call engineer (PagerDuty)
#   - warning:   Notify team (Slack)
#   - info:      Log for review (Email)
#
# Categories:
#   - slo:          SLO violations
#   - security:     Security incidents
#   - database:     Database issues
#   - performance:  Performance degradation
#   - business:     Business metric anomalies
#   - availability: Service up/down
#
# Grouping:
#   - Alerts are grouped by: alertname, cluster, service
#   - Reduces notification spam
#   - Single notification for related alerts
#
# Inhibition:
#   - Critical alerts suppress warnings
#   - ServiceDown suppresses all other alerts for that service
#   - SLOViolation suppresses ErrorBudgetLow
#
# Repeat Intervals:
#   - Critical: 1 hour
#   - SLO: 2 hours
#   - Warning: 6 hours
#   - Info: 24 hours
#
# ============================================================================
