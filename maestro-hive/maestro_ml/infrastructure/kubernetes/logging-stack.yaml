# Centralized Logging with Loki + Promtail
# Lightweight alternative to ELK stack for Kubernetes

apiVersion: v1
kind: Namespace
metadata:
  name: logging

---
# Loki StatefulSet (log aggregation)
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: logging
spec:
  serviceName: loki
  replicas: 2
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 10001
        runAsGroup: 10001
        fsGroup: 10001
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: loki
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        image: grafana/loki:2.9.3
        args:
        - -config.file=/etc/loki/loki.yaml
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9095
          name: grpc
        volumeMounts:
        - name: config
          mountPath: /etc/loki
        - name: storage
          mountPath: /loki
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: loki-config
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi

---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: logging
spec:
  type: ClusterIP
  ports:
  - port: 3100
    targetPort: 3100
    name: http
  - port: 9095
    targetPort: 9095
    name: grpc
  selector:
    app: loki

---
# Loki Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: logging
data:
  loki.yaml: |
    auth_enabled: false

    server:
      http_listen_port: 3100
      grpc_listen_port: 9095

    common:
      path_prefix: /loki
      storage:
        filesystem:
          chunks_directory: /loki/chunks
          rules_directory: /loki/rules
      replication_factor: 1
      ring:
        instance_addr: 127.0.0.1
        kvstore:
          store: inmemory

    schema_config:
      configs:
        - from: 2024-01-01
          store: boltdb-shipper
          object_store: filesystem
          schema: v12
          index:
            prefix: index_
            period: 24h

    ruler:
      alertmanager_url: http://prometheus-kube-prometheus-alertmanager.monitoring:9093

    # Retention (delete logs older than 30 days)
    limits_config:
      retention_period: 720h
      ingestion_rate_mb: 10
      ingestion_burst_size_mb: 20
      max_streams_per_user: 10000
      max_global_streams_per_user: 50000

    chunk_store_config:
      max_look_back_period: 720h

    table_manager:
      retention_deletes_enabled: true
      retention_period: 720h

    compactor:
      working_directory: /loki/compactor
      shared_store: filesystem
      retention_enabled: true
      retention_delete_delay: 2h
      retention_delete_worker_count: 150

---
# Promtail DaemonSet (log collector)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: logging
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: promtail
        image: grafana/promtail:2.9.3
        args:
        - -config.file=/etc/promtail/promtail.yaml
        env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        securityContext:
          runAsUser: 0
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
            add:
            - DAC_READ_SEARCH
        volumeMounts:
        - name: config
          mountPath: /etc/promtail
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: positions
          mountPath: /run/promtail
        resources:
          requests:
            memory: "128Mi"
            cpu: "50m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        securityContext:
          runAsUser: 0
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: positions
        hostPath:
          path: /run/promtail
          type: DirectoryOrCreate
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
        operator: Exists

---
# Promtail Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: logging
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    positions:
      filename: /run/promtail/positions.yaml

    clients:
      - url: http://loki:3100/loki/api/v1/push

    scrape_configs:
      # Kubernetes pod logs
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        pipeline_stages:
          - docker: {}
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: __host__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            replacement: $1
            separator: /
            source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_pod_name
            target_label: job
          - action: replace
            source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_container_name
            target_label: container
          - replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels:
              - __meta_kubernetes_pod_uid
              - __meta_kubernetes_pod_container_name
            target_label: __path__

      # ML Platform specific logs
      - job_name: ml-platform
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - ml-platform
                - airflow
                - feast
        pipeline_stages:
          - docker: {}
          - match:
              selector: '{app="airflow"}'
              stages:
              - regex:
                  expression: '(?P<level>(INFO|WARNING|ERROR|CRITICAL))'
              - labels:
                  level:
          - match:
              selector: '{app="mlflow"}'
              stages:
              - json:
                  expressions:
                    level: level
                    message: message
              - labels:
                  level:
        relabel_configs:
          - source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod
          - source_labels:
              - __meta_kubernetes_pod_container_name
            target_label: container
          - source_labels:
              - __meta_kubernetes_pod_label_app
            target_label: app

---
# Promtail ServiceAccount
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: logging

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "watch", "list"]
- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail
subjects:
- kind: ServiceAccount
  name: promtail
  namespace: logging

---
# Grafana Loki DataSource
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-grafana-datasource
  namespace: monitoring
  labels:
    grafana_datasource: "1"
data:
  loki-datasource.yaml: |
    apiVersion: 1
    datasources:
      - name: Loki
        type: loki
        access: proxy
        url: http://loki.logging.svc.cluster.local:3100
        jsonData:
          maxLines: 1000
          derivedFields:
            # Extract trace IDs from logs
            - datasourceUid: tempo
              matcherRegex: "trace_id=(\\w+)"
              name: TraceID
              url: "$${__value.raw}"
        isDefault: false
        editable: true

---
# ServiceMonitor for Loki metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: loki
  namespace: logging
  labels:
    app: loki
spec:
  selector:
    matchLabels:
      app: loki
  endpoints:
  - port: http
    path: /metrics
    interval: 30s

---
# ServiceMonitor for Promtail metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: promtail
  namespace: logging
  labels:
    app: promtail
spec:
  selector:
    matchLabels:
      app: promtail
  endpoints:
  - port: http-metrics
    path: /metrics
    interval: 30s

---
# Promtail Service for metrics
apiVersion: v1
kind: Service
metadata:
  name: promtail
  namespace: logging
spec:
  clusterIP: None
  ports:
  - name: http-metrics
    port: 9080
    targetPort: 9080
  selector:
    app: promtail

---
# PrometheusRule for Loki alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: loki-alerts
  namespace: logging
  labels:
    prometheus: kube-prometheus
spec:
  groups:
  - name: loki
    interval: 30s
    rules:
    - alert: LokiDown
      expr: up{job="loki"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Loki instance down"
        description: "Loki instance {{ $labels.instance }} is down"

    - alert: LokiHighIngestionRate
      expr: rate(loki_ingester_bytes_received_total[5m]) > 10485760  # 10MB/s
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "High log ingestion rate"
        description: "Loki ingestion rate is {{ $value | humanize }}B/s"

    - alert: LokiStorageNearFull
      expr: (loki_storage_bytes_used / loki_storage_bytes_total) > 0.85
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Loki storage nearly full"
        description: "Loki storage is {{ $value | humanizePercentage }} full"

    - alert: PromtailDown
      expr: up{job="promtail"} == 0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Promtail instance down"
        description: "Promtail instance {{ $labels.instance }} is down"

    - alert: PromtailFileReadErrors
      expr: rate(promtail_file_read_errors_total[5m]) > 0
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Promtail file read errors"
        description: "Promtail is experiencing file read errors on {{ $labels.instance }}"
