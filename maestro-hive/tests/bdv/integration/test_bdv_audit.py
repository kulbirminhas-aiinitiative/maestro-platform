"""
BDV Phase 2C: Test Suite - BDV Audit (Comprehensive Coverage & Compliance Tracking)

Test IDs: BDV-601 to BDV-630 (30 tests)

This comprehensive test suite implements audit capabilities for BDV scenarios:
- Coverage metrics (scenario, endpoint, contract, step, requirement traceability)
- Contract compliance validation and scoring
- Multi-format audit report generation (JSON, HTML, Markdown, PDF)
- Violation detection (missing tags, outdated versions, flaky tests, orphaned steps)
- Integration with BDV Runner, FlakeDetector, and ContractRegistry
- Performance optimization for large-scale audits

Test Categories:
1. Coverage Metrics (BDV-601 to BDV-606): 6 tests
2. Contract Compliance (BDV-607 to BDV-612): 6 tests
3. Audit Report Generation (BDV-613 to BDV-618): 6 tests
4. Violation Detection (BDV-619 to BDV-624): 6 tests
5. Integration & Performance (BDV-625 to BDV-630): 6 tests

Author: Claude Code Implementation
Date: 2025-10-13
Version: 1.0.0
"""

import pytest
import json
import time
import re
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional, Set, Tuple
from enum import Enum
from unittest.mock import Mock, patch, MagicMock
from collections import defaultdict


# ============================================================================
# Core Data Models
# ============================================================================

class ViolationType(str, Enum):
    """Types of audit violations"""
    MISSING_CONTRACT_TAG = "MISSING_CONTRACT_TAG"
    OUTDATED_CONTRACT_VERSION = "OUTDATED_CONTRACT_VERSION"
    FAILED_SCENARIO = "FAILED_SCENARIO"
    QUARANTINED_SCENARIO = "QUARANTINED_SCENARIO"
    STEP_DEFINITION_CONFLICT = "STEP_DEFINITION_CONFLICT"
    ORPHANED_STEP = "ORPHANED_STEP"
    INVALID_CONTRACT_VERSION = "INVALID_CONTRACT_VERSION"
    CONTRACT_NOT_LOCKED = "CONTRACT_NOT_LOCKED"


class ViolationSeverity(str, Enum):
    """Severity levels for violations"""
    ERROR = "ERROR"
    WARNING = "WARNING"
    INFO = "INFO"


@dataclass
class CoverageMetrics:
    """Coverage metrics for BDV audit"""
    scenario_coverage: float  # executed_scenarios / total_scenarios
    endpoint_coverage: float  # tested_endpoints / total_endpoints
    contract_coverage: float  # contracts_with_tests / total_contracts
    step_coverage: float  # unique_steps_used / total_steps_defined
    requirement_coverage: float  # scenarios_with_requirements / total_scenarios

    total_scenarios: int = 0
    executed_scenarios: int = 0
    total_endpoints: int = 0
    tested_endpoints: int = 0
    total_contracts: int = 0
    contracts_with_tests: int = 0
    total_steps_defined: int = 0
    unique_steps_used: int = 0
    scenarios_with_requirements: int = 0

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class ComplianceMetrics:
    """Contract compliance metrics"""
    contract_compliance_score: float  # compliant_scenarios / total_scenarios
    tagged_scenarios: int
    untagged_scenarios: int
    valid_contract_versions: int
    invalid_contract_versions: int
    locked_contracts: int
    draft_contracts: int

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class Violation:
    """Represents an audit violation"""
    type: ViolationType
    severity: ViolationSeverity
    scenario: Optional[str]
    description: str
    recommendation: str
    file_path: Optional[str] = None
    line_number: Optional[int] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            'type': self.type.value,
            'severity': self.severity.value,
            'scenario': self.scenario,
            'description': self.description,
            'recommendation': self.recommendation,
            'file_path': self.file_path,
            'line_number': self.line_number
        }


@dataclass
class ExecutionSummary:
    """Summary of scenario execution results"""
    total_scenarios: int
    passing: int
    failing: int
    quarantined: int
    skipped: int
    pass_rate: float

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class HistoricalTrend:
    """Historical trend data for coverage metrics"""
    timestamp: str
    scenario_coverage: float
    contract_compliance: float
    total_violations: int

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class AuditReport:
    """Comprehensive BDV audit report"""
    audit_id: str
    timestamp: str
    coverage: CoverageMetrics
    compliance: ComplianceMetrics
    violations: List[Violation]
    summary: ExecutionSummary
    trends: List[HistoricalTrend] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            'audit_id': self.audit_id,
            'timestamp': self.timestamp,
            'coverage': self.coverage.to_dict(),
            'compliance': self.compliance.to_dict(),
            'violations': [v.to_dict() for v in self.violations],
            'summary': self.summary.to_dict(),
            'trends': [t.to_dict() for t in self.trends],
            'recommendations': self.recommendations
        }


# ============================================================================
# Coverage Calculator
# ============================================================================

class CoverageCalculator:
    """
    Calculates various coverage metrics for BDV audit.

    Metrics:
    - Scenario coverage: executed vs total scenarios
    - Endpoint coverage: tested endpoints from OpenAPI specs
    - Contract coverage: contracts with tests
    - Step coverage: unique steps used vs defined
    - Requirement traceability: scenarios linked to requirements
    """

    def __init__(self):
        self.scenarios: List[Dict[str, Any]] = []
        self.openapi_specs: Dict[str, Dict[str, Any]] = {}
        self.step_definitions: Set[str] = set()
        self.step_usage: Set[str] = set()
        self.requirements_map: Dict[str, List[str]] = {}

    def add_scenario(self, scenario: Dict[str, Any]):
        """Add scenario for coverage tracking"""
        self.scenarios.append(scenario)

    def add_openapi_spec(self, contract_name: str, spec: Dict[str, Any]):
        """Add OpenAPI spec for endpoint coverage"""
        self.openapi_specs[contract_name] = spec

    def add_step_definition(self, step_pattern: str):
        """Add step definition pattern"""
        self.step_definitions.add(step_pattern)

    def add_step_usage(self, step_text: str):
        """Track step usage in scenarios"""
        self.step_usage.add(step_text)

    def link_scenario_to_requirement(self, scenario_name: str, requirement_id: str):
        """Link scenario to requirement for traceability"""
        if scenario_name not in self.requirements_map:
            self.requirements_map[scenario_name] = []
        self.requirements_map[scenario_name].append(requirement_id)

    def calculate_coverage(self) -> CoverageMetrics:
        """Calculate all coverage metrics"""
        total_scenarios = len(self.scenarios)
        executed_scenarios = sum(1 for s in self.scenarios if s.get('executed', False))

        # Endpoint coverage from OpenAPI specs
        total_endpoints = 0
        tested_endpoints = 0
        for spec in self.openapi_specs.values():
            paths = spec.get('paths', {})
            for path, methods in paths.items():
                total_endpoints += len(methods)
                # Count as tested if any scenario tests this endpoint
                for scenario in self.scenarios:
                    if scenario.get('tested_endpoint') == path:
                        tested_endpoints += 1
                        break

        # Contract coverage
        contracts_mentioned = set()
        for scenario in self.scenarios:
            contract_tag = scenario.get('contract_tag')
            if contract_tag:
                # Extract contract name from tag format: contract:AuthAPI:v1.2.0
                parts = contract_tag.split(':')
                if len(parts) >= 2:
                    contract_name = parts[1]
                    contracts_mentioned.add(contract_name)

        total_contracts = len(self.openapi_specs)
        contracts_with_tests = len(contracts_mentioned & set(self.openapi_specs.keys()))

        # Step coverage
        total_steps_defined = len(self.step_definitions)
        unique_steps_used = len(self.step_usage)

        # Requirement coverage
        scenarios_with_requirements = len(self.requirements_map)

        # Calculate percentages
        scenario_coverage = executed_scenarios / total_scenarios if total_scenarios > 0 else 0.0
        endpoint_coverage = tested_endpoints / total_endpoints if total_endpoints > 0 else 0.0
        contract_coverage = contracts_with_tests / total_contracts if total_contracts > 0 else 0.0
        step_coverage = unique_steps_used / total_steps_defined if total_steps_defined > 0 else 0.0
        requirement_coverage = scenarios_with_requirements / total_scenarios if total_scenarios > 0 else 0.0

        return CoverageMetrics(
            scenario_coverage=scenario_coverage,
            endpoint_coverage=endpoint_coverage,
            contract_coverage=contract_coverage,
            step_coverage=step_coverage,
            requirement_coverage=requirement_coverage,
            total_scenarios=total_scenarios,
            executed_scenarios=executed_scenarios,
            total_endpoints=total_endpoints,
            tested_endpoints=tested_endpoints,
            total_contracts=total_contracts,
            contracts_with_tests=contracts_with_tests,
            total_steps_defined=total_steps_defined,
            unique_steps_used=unique_steps_used,
            scenarios_with_requirements=scenarios_with_requirements
        )

    def calculate_historical_trends(
        self,
        previous_reports: List[AuditReport]
    ) -> List[HistoricalTrend]:
        """Calculate historical trends from previous audit reports"""
        trends = []
        for report in previous_reports:
            trends.append(HistoricalTrend(
                timestamp=report.timestamp,
                scenario_coverage=report.coverage.scenario_coverage,
                contract_compliance=report.compliance.contract_compliance_score,
                total_violations=len(report.violations)
            ))
        return trends


# ============================================================================
# Compliance Checker
# ============================================================================

class ComplianceChecker:
    """
    Validates contract compliance for scenarios.

    Features:
    - Validate all scenarios have contract tags
    - Verify contract versions exist in registry
    - Check contract status (DRAFT vs LOCKED)
    - Validate contract compatibility
    - Calculate compliance score
    """

    def __init__(self, contract_registry: Optional[Any] = None):
        self.contract_registry = contract_registry

    def check_scenario_compliance(
        self,
        scenario: Dict[str, Any]
    ) -> Tuple[bool, Optional[str]]:
        """
        Check if scenario is compliant with contract requirements.

        Returns: (is_compliant, error_message)
        """
        # Check for contract tag
        contract_tag = scenario.get('contract_tag')
        if not contract_tag:
            return False, "Missing contract tag (@contract:API:v1.0.0)"

        # Parse contract tag
        match = re.match(r'contract:([^:]+):v(.+)', contract_tag)
        if not match:
            return False, f"Invalid contract tag format: {contract_tag}"

        contract_name, version = match.groups()

        # Check if contract exists in registry
        if self.contract_registry:
            contract = self.contract_registry.get_contract(contract_name, version)
            if not contract:
                return False, f"Contract {contract_name}:v{version} not found in registry"

            # Check contract status
            if contract.status == "DEPRECATED":
                return False, f"Contract {contract_name}:v{version} is deprecated"

        return True, None

    def calculate_compliance_metrics(
        self,
        scenarios: List[Dict[str, Any]]
    ) -> ComplianceMetrics:
        """Calculate compliance metrics for all scenarios"""
        tagged_scenarios = 0
        untagged_scenarios = 0
        valid_contract_versions = 0
        invalid_contract_versions = 0
        locked_contracts = 0
        draft_contracts = 0

        for scenario in scenarios:
            is_compliant, error = self.check_scenario_compliance(scenario)

            if scenario.get('contract_tag'):
                tagged_scenarios += 1

                if is_compliant:
                    valid_contract_versions += 1
                else:
                    invalid_contract_versions += 1

                # Check contract status
                if self.contract_registry:
                    match = re.match(r'contract:([^:]+):v(.+)', scenario.get('contract_tag', ''))
                    if match:
                        contract_name, version = match.groups()
                        contract = self.contract_registry.get_contract(contract_name, version)
                        if contract:
                            if contract.status == "LOCKED":
                                locked_contracts += 1
                            elif contract.status == "DRAFT":
                                draft_contracts += 1
            else:
                untagged_scenarios += 1

        total_scenarios = len(scenarios)
        compliant_scenarios = valid_contract_versions
        contract_compliance_score = compliant_scenarios / total_scenarios if total_scenarios > 0 else 0.0

        return ComplianceMetrics(
            contract_compliance_score=contract_compliance_score,
            tagged_scenarios=tagged_scenarios,
            untagged_scenarios=untagged_scenarios,
            valid_contract_versions=valid_contract_versions,
            invalid_contract_versions=invalid_contract_versions,
            locked_contracts=locked_contracts,
            draft_contracts=draft_contracts
        )


# ============================================================================
# Violation Detector
# ============================================================================

class ViolationDetector:
    """
    Detects various types of violations in BDV scenarios.

    Detects:
    - Missing contract tags
    - Outdated contract versions
    - Failed scenarios (real vs flaky)
    - Quarantined scenarios
    - Step definition conflicts
    - Orphaned step definitions
    """

    def __init__(
        self,
        compliance_checker: Optional[ComplianceChecker] = None,
        flake_detector: Optional[Any] = None
    ):
        self.compliance_checker = compliance_checker
        self.flake_detector = flake_detector

    def detect_violations(
        self,
        scenarios: List[Dict[str, Any]],
        step_definitions: Set[str],
        step_usage: Set[str]
    ) -> List[Violation]:
        """Detect all types of violations"""
        violations = []

        # Detect missing contract tags
        violations.extend(self._detect_missing_contract_tags(scenarios))

        # Detect outdated contract versions
        violations.extend(self._detect_outdated_versions(scenarios))

        # Detect failed scenarios
        violations.extend(self._detect_failed_scenarios(scenarios))

        # Detect quarantined scenarios
        violations.extend(self._detect_quarantined_scenarios(scenarios))

        # Detect step definition conflicts
        violations.extend(self._detect_step_conflicts(step_definitions))

        # Detect orphaned steps
        violations.extend(self._detect_orphaned_steps(step_definitions, step_usage))

        return violations

    def _detect_missing_contract_tags(
        self,
        scenarios: List[Dict[str, Any]]
    ) -> List[Violation]:
        """Detect scenarios without contract tags"""
        violations = []
        for scenario in scenarios:
            if not scenario.get('contract_tag'):
                violations.append(Violation(
                    type=ViolationType.MISSING_CONTRACT_TAG,
                    severity=ViolationSeverity.WARNING,
                    scenario=scenario.get('name'),
                    description=f"Scenario '{scenario.get('name')}' missing contract tag",
                    recommendation="Add @contract tag with version (e.g., @contract:API:v1.0.0)",
                    file_path=scenario.get('file_path')
                ))
        return violations

    def _detect_outdated_versions(
        self,
        scenarios: List[Dict[str, Any]]
    ) -> List[Violation]:
        """Detect scenarios using outdated contract versions"""
        violations = []
        # Check if contract versions are outdated (placeholder logic)
        for scenario in scenarios:
            contract_tag = scenario.get('contract_tag')
            if contract_tag and 'v0.' in contract_tag:  # Example: v0.x is considered outdated
                violations.append(Violation(
                    type=ViolationType.OUTDATED_CONTRACT_VERSION,
                    severity=ViolationSeverity.WARNING,
                    scenario=scenario.get('name'),
                    description=f"Scenario using outdated version: {contract_tag}",
                    recommendation="Update to latest stable version",
                    file_path=scenario.get('file_path')
                ))
        return violations

    def _detect_failed_scenarios(
        self,
        scenarios: List[Dict[str, Any]]
    ) -> List[Violation]:
        """Detect failed scenarios"""
        violations = []
        for scenario in scenarios:
            if scenario.get('status') == 'failed':
                # Check if it's a flaky test
                is_flaky = scenario.get('flaky', False)
                severity = ViolationSeverity.WARNING if is_flaky else ViolationSeverity.ERROR

                violations.append(Violation(
                    type=ViolationType.FAILED_SCENARIO,
                    severity=severity,
                    scenario=scenario.get('name'),
                    description=f"Scenario failed: {scenario.get('error', 'Unknown error')}",
                    recommendation="Fix failing scenario" if not is_flaky else "Address flaky test (quarantine if needed)",
                    file_path=scenario.get('file_path')
                ))
        return violations

    def _detect_quarantined_scenarios(
        self,
        scenarios: List[Dict[str, Any]]
    ) -> List[Violation]:
        """Detect quarantined scenarios still in codebase"""
        violations = []
        for scenario in scenarios:
            if scenario.get('quarantined', False):
                violations.append(Violation(
                    type=ViolationType.QUARANTINED_SCENARIO,
                    severity=ViolationSeverity.INFO,
                    scenario=scenario.get('name'),
                    description=f"Scenario is quarantined due to flakiness",
                    recommendation="Fix and unquarantine, or remove if obsolete",
                    file_path=scenario.get('file_path')
                ))
        return violations

    def _detect_step_conflicts(
        self,
        step_definitions: Set[str]
    ) -> List[Violation]:
        """Detect step definition conflicts (duplicate patterns)"""
        violations = []
        seen = {}
        for step in step_definitions:
            # Simplified conflict detection
            normalized = step.lower().strip()
            if normalized in seen:
                violations.append(Violation(
                    type=ViolationType.STEP_DEFINITION_CONFLICT,
                    severity=ViolationSeverity.ERROR,
                    scenario=None,
                    description=f"Duplicate step definition: {step}",
                    recommendation="Remove or rename one of the conflicting step definitions"
                ))
            seen[normalized] = step
        return violations

    def _detect_orphaned_steps(
        self,
        step_definitions: Set[str],
        step_usage: Set[str]
    ) -> List[Violation]:
        """Detect orphaned step definitions (never used)"""
        violations = []
        for step_def in step_definitions:
            # Check if step is used
            used = any(step_def.lower() in usage.lower() for usage in step_usage)
            if not used:
                violations.append(Violation(
                    type=ViolationType.ORPHANED_STEP,
                    severity=ViolationSeverity.INFO,
                    scenario=None,
                    description=f"Orphaned step definition (never used): {step_def}",
                    recommendation="Remove unused step definition or add scenarios using it"
                ))
        return violations


# ============================================================================
# Report Generator
# ============================================================================

class ReportGenerator:
    """
    Generates audit reports in multiple formats.

    Formats:
    - JSON: Machine-readable format for automation
    - HTML: Human-readable with visualizations
    - Markdown: Documentation format
    - PDF: Stakeholder-ready format
    """

    def generate_json_report(self, audit_report: AuditReport) -> str:
        """Generate JSON report"""
        return json.dumps(audit_report.to_dict(), indent=2)

    def generate_html_report(self, audit_report: AuditReport) -> str:
        """Generate HTML report with visualizations"""
        html = f"""<!DOCTYPE html>
<html>
<head>
    <title>BDV Audit Report - {audit_report.audit_id}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        h1 {{ color: #333; }}
        .metric {{ display: inline-block; margin: 10px; padding: 15px; background: #f0f0f0; border-radius: 5px; }}
        .metric-value {{ font-size: 24px; font-weight: bold; color: #007bff; }}
        .violation {{ padding: 10px; margin: 5px 0; border-left: 4px solid #dc3545; background: #fff3cd; }}
        .warning {{ border-left-color: #ffc107; }}
        .info {{ border-left-color: #17a2b8; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #007bff; color: white; }}
    </style>
</head>
<body>
    <h1>BDV Audit Report</h1>
    <p><strong>Audit ID:</strong> {audit_report.audit_id}</p>
    <p><strong>Timestamp:</strong> {audit_report.timestamp}</p>

    <h2>Coverage Metrics</h2>
    <div class="metric">
        <div>Scenario Coverage</div>
        <div class="metric-value">{audit_report.coverage.scenario_coverage:.1%}</div>
    </div>
    <div class="metric">
        <div>Endpoint Coverage</div>
        <div class="metric-value">{audit_report.coverage.endpoint_coverage:.1%}</div>
    </div>
    <div class="metric">
        <div>Contract Coverage</div>
        <div class="metric-value">{audit_report.coverage.contract_coverage:.1%}</div>
    </div>
    <div class="metric">
        <div>Step Coverage</div>
        <div class="metric-value">{audit_report.coverage.step_coverage:.1%}</div>
    </div>

    <h2>Compliance Score</h2>
    <div class="metric">
        <div>Contract Compliance</div>
        <div class="metric-value">{audit_report.compliance.contract_compliance_score:.1%}</div>
    </div>

    <h2>Execution Summary</h2>
    <table>
        <tr><th>Metric</th><th>Value</th></tr>
        <tr><td>Total Scenarios</td><td>{audit_report.summary.total_scenarios}</td></tr>
        <tr><td>Passing</td><td>{audit_report.summary.passing}</td></tr>
        <tr><td>Failing</td><td>{audit_report.summary.failing}</td></tr>
        <tr><td>Quarantined</td><td>{audit_report.summary.quarantined}</td></tr>
        <tr><td>Pass Rate</td><td>{audit_report.summary.pass_rate:.1%}</td></tr>
    </table>

    <h2>Violations ({len(audit_report.violations)})</h2>
"""

        for violation in audit_report.violations:
            severity_class = violation.severity.value.lower()
            html += f"""    <div class="violation {severity_class}">
        <strong>[{violation.severity.value}] {violation.type.value}</strong>
        <p>{violation.description}</p>
        <p><em>Recommendation:</em> {violation.recommendation}</p>
    </div>
"""

        html += """</body>
</html>"""

        return html

    def generate_markdown_report(self, audit_report: AuditReport) -> str:
        """Generate Markdown report for documentation"""
        md = f"""# BDV Audit Report

**Audit ID:** {audit_report.audit_id}
**Timestamp:** {audit_report.timestamp}

## Coverage Metrics

| Metric | Coverage |
|--------|----------|
| Scenario Coverage | {audit_report.coverage.scenario_coverage:.1%} ({audit_report.coverage.executed_scenarios}/{audit_report.coverage.total_scenarios}) |
| Endpoint Coverage | {audit_report.coverage.endpoint_coverage:.1%} ({audit_report.coverage.tested_endpoints}/{audit_report.coverage.total_endpoints}) |
| Contract Coverage | {audit_report.coverage.contract_coverage:.1%} ({audit_report.coverage.contracts_with_tests}/{audit_report.coverage.total_contracts}) |
| Step Coverage | {audit_report.coverage.step_coverage:.1%} ({audit_report.coverage.unique_steps_used}/{audit_report.coverage.total_steps_defined}) |
| Requirement Traceability | {audit_report.coverage.requirement_coverage:.1%} ({audit_report.coverage.scenarios_with_requirements}/{audit_report.coverage.total_scenarios}) |

## Contract Compliance

- **Compliance Score:** {audit_report.compliance.contract_compliance_score:.1%}
- **Tagged Scenarios:** {audit_report.compliance.tagged_scenarios}
- **Untagged Scenarios:** {audit_report.compliance.untagged_scenarios}
- **Valid Contract Versions:** {audit_report.compliance.valid_contract_versions}
- **Invalid Contract Versions:** {audit_report.compliance.invalid_contract_versions}

## Execution Summary

- **Total Scenarios:** {audit_report.summary.total_scenarios}
- **Passing:** {audit_report.summary.passing}
- **Failing:** {audit_report.summary.failing}
- **Quarantined:** {audit_report.summary.quarantined}
- **Pass Rate:** {audit_report.summary.pass_rate:.1%}

## Violations ({len(audit_report.violations)})

"""

        for violation in audit_report.violations:
            md += f"""### {violation.type.value} [{violation.severity.value}]

**Scenario:** {violation.scenario or 'N/A'}
**Description:** {violation.description}
**Recommendation:** {violation.recommendation}

"""

        if audit_report.recommendations:
            md += "## Recommendations\n\n"
            for i, rec in enumerate(audit_report.recommendations, 1):
                md += f"{i}. {rec}\n"

        return md

    def generate_pdf_report(self, audit_report: AuditReport) -> bytes:
        """
        Generate PDF report for stakeholders.

        Note: In production, would use a library like ReportLab or WeasyPrint.
        For testing, returns a placeholder PDF structure.
        """
        # Placeholder PDF generation
        pdf_content = f"""PDF Report - {audit_report.audit_id}

Coverage: {audit_report.coverage.scenario_coverage:.1%}
Compliance: {audit_report.compliance.contract_compliance_score:.1%}
Violations: {len(audit_report.violations)}
"""
        return pdf_content.encode('utf-8')

    def save_report(
        self,
        audit_report: AuditReport,
        format: str,
        output_dir: Path
    ) -> Path:
        """Save report to file"""
        output_dir.mkdir(parents=True, exist_ok=True)

        if format == "json":
            content = self.generate_json_report(audit_report)
            file_path = output_dir / f"{audit_report.audit_id}.json"
            file_path.write_text(content)
        elif format == "html":
            content = self.generate_html_report(audit_report)
            file_path = output_dir / f"{audit_report.audit_id}.html"
            file_path.write_text(content)
        elif format == "markdown":
            content = self.generate_markdown_report(audit_report)
            file_path = output_dir / f"{audit_report.audit_id}.md"
            file_path.write_text(content)
        elif format == "pdf":
            content = self.generate_pdf_report(audit_report)
            file_path = output_dir / f"{audit_report.audit_id}.pdf"
            file_path.write_bytes(content)
        else:
            raise ValueError(f"Unsupported format: {format}")

        return file_path


# ============================================================================
# BDV Audit Engine
# ============================================================================

class BDVAuditEngine:
    """
    Main audit engine that orchestrates coverage calculation,
    compliance checking, violation detection, and report generation.
    """

    def __init__(
        self,
        contract_registry: Optional[Any] = None,
        bdv_runner: Optional[Any] = None,
        flake_detector: Optional[Any] = None
    ):
        self.contract_registry = contract_registry
        self.bdv_runner = bdv_runner
        self.flake_detector = flake_detector

        self.coverage_calculator = CoverageCalculator()
        self.compliance_checker = ComplianceChecker(contract_registry)
        self.violation_detector = ViolationDetector(self.compliance_checker, flake_detector)
        self.report_generator = ReportGenerator()

        self.historical_reports: List[AuditReport] = []

    def run_audit(
        self,
        scenarios: List[Dict[str, Any]],
        openapi_specs: Dict[str, Dict[str, Any]],
        step_definitions: Set[str],
        step_usage: Set[str]
    ) -> AuditReport:
        """
        Run comprehensive audit.

        Returns: AuditReport with all metrics, violations, and recommendations
        """
        audit_id = f"bdv_audit_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"
        timestamp = datetime.utcnow().isoformat() + "Z"

        # Calculate coverage metrics
        for scenario in scenarios:
            self.coverage_calculator.add_scenario(scenario)
        for name, spec in openapi_specs.items():
            self.coverage_calculator.add_openapi_spec(name, spec)
        for step_def in step_definitions:
            self.coverage_calculator.add_step_definition(step_def)
        for step in step_usage:
            self.coverage_calculator.add_step_usage(step)

        coverage = self.coverage_calculator.calculate_coverage()

        # Calculate compliance metrics
        compliance = self.compliance_checker.calculate_compliance_metrics(scenarios)

        # Detect violations
        violations = self.violation_detector.detect_violations(
            scenarios,
            step_definitions,
            step_usage
        )

        # Calculate execution summary
        total_scenarios = len(scenarios)
        passing = sum(1 for s in scenarios if s.get('status') == 'passed')
        failing = sum(1 for s in scenarios if s.get('status') == 'failed')
        quarantined = sum(1 for s in scenarios if s.get('quarantined', False))
        skipped = sum(1 for s in scenarios if s.get('status') == 'skipped')
        pass_rate = passing / total_scenarios if total_scenarios > 0 else 0.0

        summary = ExecutionSummary(
            total_scenarios=total_scenarios,
            passing=passing,
            failing=failing,
            quarantined=quarantined,
            skipped=skipped,
            pass_rate=pass_rate
        )

        # Calculate historical trends
        trends = self.coverage_calculator.calculate_historical_trends(self.historical_reports)

        # Generate recommendations
        recommendations = self._generate_recommendations(coverage, compliance, violations)

        # Create audit report
        report = AuditReport(
            audit_id=audit_id,
            timestamp=timestamp,
            coverage=coverage,
            compliance=compliance,
            violations=violations,
            summary=summary,
            trends=trends,
            recommendations=recommendations
        )

        # Store in history
        self.historical_reports.append(report)

        return report

    def run_incremental_audit(
        self,
        changed_scenarios: List[Dict[str, Any]],
        previous_report: AuditReport
    ) -> AuditReport:
        """
        Run incremental audit on only changed scenarios.
        Useful for CI/CD pipelines.
        """
        # For incremental audit, only audit changed scenarios
        # Merge with previous report data
        audit_id = f"bdv_audit_incremental_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"
        timestamp = datetime.utcnow().isoformat() + "Z"

        # Calculate coverage metrics for changed scenarios
        for scenario in changed_scenarios:
            self.coverage_calculator.add_scenario(scenario)

        coverage = self.coverage_calculator.calculate_coverage()

        # Calculate compliance metrics
        compliance = self.compliance_checker.calculate_compliance_metrics(changed_scenarios)

        # Detect violations
        violations = self.violation_detector.detect_violations(
            changed_scenarios,
            set(),
            set()
        )

        # Calculate execution summary
        total_scenarios = len(changed_scenarios)
        passing = sum(1 for s in changed_scenarios if s.get('status') == 'passed')
        failing = sum(1 for s in changed_scenarios if s.get('status') == 'failed')
        quarantined = sum(1 for s in changed_scenarios if s.get('quarantined', False))
        skipped = sum(1 for s in changed_scenarios if s.get('status') == 'skipped')
        pass_rate = passing / total_scenarios if total_scenarios > 0 else 0.0

        summary = ExecutionSummary(
            total_scenarios=total_scenarios,
            passing=passing,
            failing=failing,
            quarantined=quarantined,
            skipped=skipped,
            pass_rate=pass_rate
        )

        # Calculate historical trends
        trends = self.coverage_calculator.calculate_historical_trends(self.historical_reports)

        # Generate recommendations
        recommendations = self._generate_recommendations(coverage, compliance, violations)

        # Create incremental audit report
        report = AuditReport(
            audit_id=audit_id,
            timestamp=timestamp,
            coverage=coverage,
            compliance=compliance,
            violations=violations,
            summary=summary,
            trends=trends,
            recommendations=recommendations
        )

        # Store in history
        self.historical_reports.append(report)

        return report

    def _generate_recommendations(
        self,
        coverage: CoverageMetrics,
        compliance: ComplianceMetrics,
        violations: List[Violation]
    ) -> List[str]:
        """Generate actionable recommendations based on audit results"""
        recommendations = []

        # Coverage recommendations
        if coverage.scenario_coverage < 0.8:
            recommendations.append(
                f"Increase scenario coverage from {coverage.scenario_coverage:.1%} to at least 80%"
            )

        if coverage.endpoint_coverage < 0.9:
            recommendations.append(
                f"Improve endpoint coverage from {coverage.endpoint_coverage:.1%} to at least 90%"
            )

        if coverage.contract_coverage < 1.0:
            recommendations.append(
                f"Add tests for {coverage.total_contracts - coverage.contracts_with_tests} contracts without tests"
            )

        # Compliance recommendations
        if compliance.untagged_scenarios > 0:
            recommendations.append(
                f"Add contract tags to {compliance.untagged_scenarios} untagged scenarios"
            )

        if compliance.contract_compliance_score < 0.95:
            recommendations.append(
                f"Improve contract compliance from {compliance.contract_compliance_score:.1%} to at least 95%"
            )

        # Violation recommendations
        error_violations = [v for v in violations if v.severity == ViolationSeverity.ERROR]
        if error_violations:
            recommendations.append(
                f"Fix {len(error_violations)} ERROR-level violations immediately"
            )

        return recommendations


# ============================================================================
# Test Fixtures
# ============================================================================

@pytest.fixture
def sample_scenarios():
    """Generate sample scenarios for testing"""
    return [
        {
            'name': 'User Login Success',
            'contract_tag': 'contract:AuthAPI:v1.2.0',
            'status': 'passed',
            'executed': True,
            'tested_endpoint': '/auth/login',
            'file_path': 'features/auth/login.feature',
            'flaky': False,
            'quarantined': False
        },
        {
            'name': 'User Login Failure',
            'contract_tag': 'contract:AuthAPI:v1.2.0',
            'status': 'passed',
            'executed': True,
            'tested_endpoint': '/auth/login',
            'file_path': 'features/auth/login.feature',
            'flaky': False,
            'quarantined': False
        },
        {
            'name': 'Get User Profile',
            'contract_tag': 'contract:UserAPI:v2.0.0',
            'status': 'failed',
            'executed': True,
            'tested_endpoint': '/users/profile',
            'file_path': 'features/users/profile.feature',
            'error': 'Timeout waiting for response',
            'flaky': True,
            'quarantined': False
        },
        {
            'name': 'Update User Profile',
            'status': 'passed',
            'executed': True,
            'tested_endpoint': '/users/profile',
            'file_path': 'features/users/profile.feature',
            'flaky': False,
            'quarantined': False
        },
        {
            'name': 'Delete User Account',
            'contract_tag': 'contract:UserAPI:v0.9.0',  # Outdated version
            'status': 'skipped',
            'executed': False,
            'tested_endpoint': '/users',
            'file_path': 'features/users/delete.feature',
            'flaky': False,
            'quarantined': True
        }
    ]


@pytest.fixture
def sample_openapi_specs():
    """Generate sample OpenAPI specifications"""
    return {
        'AuthAPI': {
            'openapi': '3.0.0',
            'paths': {
                '/auth/login': {
                    'post': {'summary': 'Login'},
                    'get': {'summary': 'Check login status'}
                },
                '/auth/logout': {
                    'post': {'summary': 'Logout'}
                }
            }
        },
        'UserAPI': {
            'openapi': '3.0.0',
            'paths': {
                '/users/profile': {
                    'get': {'summary': 'Get profile'},
                    'put': {'summary': 'Update profile'}
                },
                '/users': {
                    'get': {'summary': 'List users'},
                    'post': {'summary': 'Create user'},
                    'delete': {'summary': 'Delete user'}
                }
            }
        },
        'PaymentAPI': {
            'openapi': '3.0.0',
            'paths': {
                '/payments': {
                    'post': {'summary': 'Process payment'}
                }
            }
        }
    }


@pytest.fixture
def sample_step_definitions():
    """Generate sample step definitions"""
    return {
        'Given I am on the login page',
        'When I enter valid credentials',
        'Then I should be logged in',
        'Given I am authenticated',
        'When I view my profile',
        'Then I should see my details',
        'When I update my profile',
        'When I delete my account',
        'Given I am an admin user',  # Orphaned step (never used)
    }


@pytest.fixture
def sample_step_usage():
    """Generate sample step usage"""
    return {
        'Given I am on the login page',
        'When I enter valid credentials',
        'Then I should be logged in',
        'Given I am authenticated',
        'When I view my profile',
        'Then I should see my details',
        'When I update my profile',
        'When I delete my account',
    }


@pytest.fixture
def mock_contract_registry():
    """Mock contract registry"""
    class MockContractRegistry:
        def get_contract(self, name, version):
            contracts = {
                ('AuthAPI', '1.2.0'): Mock(status='LOCKED'),
                ('UserAPI', '2.0.0'): Mock(status='LOCKED'),
                ('UserAPI', '0.9.0'): Mock(status='DRAFT'),
            }
            return contracts.get((name, version))

    return MockContractRegistry()


@pytest.fixture
def audit_engine(mock_contract_registry):
    """Create BDV audit engine"""
    return BDVAuditEngine(contract_registry=mock_contract_registry)


# ============================================================================
# Test Suite 1: Coverage Metrics (BDV-601 to BDV-606)
# ============================================================================

@pytest.mark.bdv
@pytest.mark.integration
class TestCoverageMetrics:
    """Coverage metrics tests (BDV-601 to BDV-606)"""

    def test_bdv_601_scenario_coverage_calculation(self, sample_scenarios):
        """BDV-601: Scenario coverage = executed_scenarios / total_scenarios"""
        calculator = CoverageCalculator()
        for scenario in sample_scenarios:
            calculator.add_scenario(scenario)

        coverage = calculator.calculate_coverage()

        # 4 executed out of 5 total
        assert coverage.total_scenarios == 5
        assert coverage.executed_scenarios == 4
        assert coverage.scenario_coverage == 0.8

    def test_bdv_602_endpoint_coverage_from_openapi(
        self,
        sample_scenarios,
        sample_openapi_specs
    ):
        """BDV-602: Endpoint coverage from OpenAPI = tested_endpoints / total_endpoints"""
        calculator = CoverageCalculator()
        for scenario in sample_scenarios:
            calculator.add_scenario(scenario)
        for name, spec in sample_openapi_specs.items():
            calculator.add_openapi_spec(name, spec)

        coverage = calculator.calculate_coverage()

        # Total endpoints: 3 (AuthAPI) + 5 (UserAPI) + 1 (PaymentAPI) = 9
        # Tested endpoints: /auth/login, /users/profile, /users = 3
        assert coverage.total_endpoints == 9
        assert coverage.tested_endpoints >= 2  # At least login and profile

    def test_bdv_603_contract_coverage_calculation(
        self,
        sample_scenarios,
        sample_openapi_specs
    ):
        """BDV-603: Contract coverage = contracts_with_tests / total_contracts"""
        calculator = CoverageCalculator()
        for scenario in sample_scenarios:
            calculator.add_scenario(scenario)
        for name, spec in sample_openapi_specs.items():
            calculator.add_openapi_spec(name, spec)

        coverage = calculator.calculate_coverage()

        # Total contracts: 3 (AuthAPI, UserAPI, PaymentAPI)
        # Contracts with tests: 2 (AuthAPI, UserAPI)
        assert coverage.total_contracts == 3
        assert coverage.contracts_with_tests == 2
        assert coverage.contract_coverage == 2/3

    def test_bdv_604_step_coverage_calculation(
        self,
        sample_scenarios,
        sample_step_definitions,
        sample_step_usage
    ):
        """BDV-604: Step coverage = unique_steps_used / total_steps_defined"""
        calculator = CoverageCalculator()
        for scenario in sample_scenarios:
            calculator.add_scenario(scenario)
        for step_def in sample_step_definitions:
            calculator.add_step_definition(step_def)
        for step in sample_step_usage:
            calculator.add_step_usage(step)

        coverage = calculator.calculate_coverage()

        # Total step definitions: 9
        # Unique steps used: 8 (admin user step is orphaned)
        assert coverage.total_steps_defined == 9
        assert coverage.unique_steps_used == 8
        assert coverage.step_coverage == 8/9

    def test_bdv_605_requirement_traceability(self, sample_scenarios):
        """BDV-605: Requirement traceability = scenarios_with_requirements / total_scenarios"""
        calculator = CoverageCalculator()
        for scenario in sample_scenarios:
            calculator.add_scenario(scenario)

        # Link scenarios to requirements
        calculator.link_scenario_to_requirement('User Login Success', 'REQ-001')
        calculator.link_scenario_to_requirement('User Login Failure', 'REQ-001')
        calculator.link_scenario_to_requirement('Get User Profile', 'REQ-002')

        coverage = calculator.calculate_coverage()

        # 3 scenarios linked to requirements out of 5 total
        assert coverage.scenarios_with_requirements == 3
        assert coverage.requirement_coverage == 3/5

    def test_bdv_606_coverage_trends_over_time(self, audit_engine, sample_scenarios):
        """BDV-606: Coverage trends tracked historically"""
        # Run multiple audits to generate trends
        report1 = audit_engine.run_audit(sample_scenarios[:3], {}, set(), set())
        time.sleep(0.1)
        report2 = audit_engine.run_audit(sample_scenarios[:4], {}, set(), set())
        time.sleep(0.1)
        report3 = audit_engine.run_audit(sample_scenarios, {}, set(), set())

        # Check trends are tracked
        assert len(audit_engine.historical_reports) == 3

        # Latest report should have trends from previous reports
        trends = audit_engine.coverage_calculator.calculate_historical_trends(
            audit_engine.historical_reports[:2]
        )
        assert len(trends) == 2


# ============================================================================
# Test Suite 2: Contract Compliance (BDV-607 to BDV-612)
# ============================================================================

@pytest.mark.bdv
@pytest.mark.integration
class TestContractCompliance:
    """Contract compliance tests (BDV-607 to BDV-612)"""

    def test_bdv_607_validate_scenarios_have_contract_tags(
        self,
        mock_contract_registry,
        sample_scenarios
    ):
        """BDV-607: Validate all scenarios tagged with contract versions"""
        checker = ComplianceChecker(mock_contract_registry)

        tagged_count = sum(1 for s in sample_scenarios if s.get('contract_tag'))

        # 4 out of 5 scenarios have contract tags
        assert tagged_count == 4

    def test_bdv_608_detect_scenarios_without_contract_tags(self, sample_scenarios):
        """BDV-608: Detect scenarios without contract tags (WARNING)"""
        detector = ViolationDetector()
        violations = detector._detect_missing_contract_tags(sample_scenarios)

        # 1 scenario without contract tag
        assert len(violations) == 1
        assert violations[0].type == ViolationType.MISSING_CONTRACT_TAG
        assert violations[0].severity == ViolationSeverity.WARNING

    def test_bdv_609_verify_contract_versions_exist_in_registry(
        self,
        mock_contract_registry,
        sample_scenarios
    ):
        """BDV-609: Verify contract versions exist in registry"""
        checker = ComplianceChecker(mock_contract_registry)

        for scenario in sample_scenarios:
            if scenario.get('contract_tag'):
                is_compliant, error = checker.check_scenario_compliance(scenario)
                # Should validate against registry
                if scenario['name'] in ['User Login Success', 'User Login Failure', 'Get User Profile']:
                    assert is_compliant or error is not None

    def test_bdv_610_check_contract_status_draft_vs_locked(
        self,
        mock_contract_registry,
        sample_scenarios
    ):
        """BDV-610: Check contract status (DRAFT vs LOCKED)"""
        checker = ComplianceChecker(mock_contract_registry)
        compliance = checker.calculate_compliance_metrics(sample_scenarios)

        # AuthAPI:v1.2.0 and UserAPI:v2.0.0 are LOCKED
        # UserAPI:v0.9.0 is DRAFT
        assert compliance.locked_contracts >= 2
        assert compliance.draft_contracts >= 1

    def test_bdv_611_validate_contract_compatibility(
        self,
        mock_contract_registry,
        sample_scenarios
    ):
        """BDV-611: Validate contract compatibility (breaking changes)"""
        # Check for outdated versions (breaking changes indicator)
        detector = ViolationDetector()
        violations = detector._detect_outdated_versions(sample_scenarios)

        # v0.9.0 is outdated
        assert len(violations) >= 1
        outdated = [v for v in violations if v.type == ViolationType.OUTDATED_CONTRACT_VERSION]
        assert len(outdated) >= 1

    def test_bdv_612_contract_compliance_score(
        self,
        mock_contract_registry,
        sample_scenarios
    ):
        """BDV-612: Contract compliance score = compliant_scenarios / total_scenarios"""
        checker = ComplianceChecker(mock_contract_registry)
        compliance = checker.calculate_compliance_metrics(sample_scenarios)

        # Should calculate compliance score
        assert 0.0 <= compliance.contract_compliance_score <= 1.0
        assert compliance.tagged_scenarios == 4
        assert compliance.untagged_scenarios == 1


# ============================================================================
# Test Suite 3: Audit Report Generation (BDV-613 to BDV-618)
# ============================================================================

@pytest.mark.bdv
@pytest.mark.integration
class TestAuditReportGeneration:
    """Audit report generation tests (BDV-613 to BDV-618)"""

    def test_bdv_613_generate_json_report(
        self,
        audit_engine,
        sample_scenarios,
        sample_openapi_specs,
        sample_step_definitions,
        sample_step_usage
    ):
        """BDV-613: Generate JSON report with full audit data"""
        report = audit_engine.run_audit(
            sample_scenarios,
            sample_openapi_specs,
            sample_step_definitions,
            sample_step_usage
        )

        json_report = audit_engine.report_generator.generate_json_report(report)

        # Validate JSON structure
        data = json.loads(json_report)
        assert 'audit_id' in data
        assert 'timestamp' in data
        assert 'coverage' in data
        assert 'compliance' in data
        assert 'violations' in data
        assert 'summary' in data

    def test_bdv_614_generate_html_report(
        self,
        audit_engine,
        sample_scenarios,
        sample_openapi_specs,
        sample_step_definitions,
        sample_step_usage
    ):
        """BDV-614: Generate HTML report with visualizations"""
        report = audit_engine.run_audit(
            sample_scenarios,
            sample_openapi_specs,
            sample_step_definitions,
            sample_step_usage
        )

        html_report = audit_engine.report_generator.generate_html_report(report)

        # Validate HTML content
        assert '<!DOCTYPE html>' in html_report
        assert '<title>BDV Audit Report' in html_report
        assert 'Coverage Metrics' in html_report
        assert 'Compliance Score' in html_report

    def test_bdv_615_generate_markdown_report(
        self,
        audit_engine,
        sample_scenarios,
        sample_openapi_specs,
        sample_step_definitions,
        sample_step_usage
    ):
        """BDV-615: Generate Markdown report for documentation"""
        report = audit_engine.run_audit(
            sample_scenarios,
            sample_openapi_specs,
            sample_step_definitions,
            sample_step_usage
        )

        md_report = audit_engine.report_generator.generate_markdown_report(report)

        # Validate Markdown structure
        assert '# BDV Audit Report' in md_report
        assert '## Coverage Metrics' in md_report
        assert '## Contract Compliance' in md_report
        assert '| Metric | Coverage |' in md_report

    def test_bdv_616_generate_pdf_report(
        self,
        audit_engine,
        sample_scenarios,
        sample_openapi_specs,
        sample_step_definitions,
        sample_step_usage
    ):
        """BDV-616: Generate PDF report for stakeholders"""
        report = audit_engine.run_audit(
            sample_scenarios,
            sample_openapi_specs,
            sample_step_definitions,
            sample_step_usage
        )

        pdf_report = audit_engine.report_generator.generate_pdf_report(report)

        # Validate PDF content (placeholder implementation)
        assert isinstance(pdf_report, bytes)
        assert len(pdf_report) > 0

    def test_bdv_617_report_includes_all_sections(
        self,
        audit_engine,
        sample_scenarios,
        sample_openapi_specs,
        sample_step_definitions,
        sample_step_usage
    ):
        """BDV-617: Report includes: coverage, violations, recommendations"""
        report = audit_engine.run_audit(
            sample_scenarios,
            sample_openapi_specs,
            sample_step_definitions,
            sample_step_usage
        )

        # Validate report structure
        assert report.coverage is not None
        assert report.compliance is not None
        assert isinstance(report.violations, list)
        assert report.summary is not None
        assert isinstance(report.recommendations, list)

    def test_bdv_618_report_generation_performance(
        self,
        audit_engine,
        sample_scenarios,
        sample_openapi_specs,
        sample_step_definitions,
        sample_step_usage
    ):
        """BDV-618: Report generation performance < 5 seconds"""
        start = time.time()

        report = audit_engine.run_audit(
            sample_scenarios,
            sample_openapi_specs,
            sample_step_definitions,
            sample_step_usage
        )

        # Generate all report formats
        audit_engine.report_generator.generate_json_report(report)
        audit_engine.report_generator.generate_html_report(report)
        audit_engine.report_generator.generate_markdown_report(report)
        audit_engine.report_generator.generate_pdf_report(report)

        elapsed = time.time() - start

        assert elapsed < 5.0, f"Report generation took {elapsed:.2f}s, should be < 5s"


# ============================================================================
# Test Suite 4: Violation Detection (BDV-619 to BDV-624)
# ============================================================================

@pytest.mark.bdv
@pytest.mark.integration
class TestViolationDetection:
    """Violation detection tests (BDV-619 to BDV-624)"""

    def test_bdv_619_detect_missing_contract_tags(self, sample_scenarios):
        """BDV-619: Detect missing contract tags"""
        detector = ViolationDetector()
        violations = detector._detect_missing_contract_tags(sample_scenarios)

        assert len(violations) >= 1
        assert all(v.type == ViolationType.MISSING_CONTRACT_TAG for v in violations)
        assert all(v.severity == ViolationSeverity.WARNING for v in violations)

    def test_bdv_620_detect_outdated_contract_versions(self, sample_scenarios):
        """BDV-620: Detect outdated contract versions"""
        detector = ViolationDetector()
        violations = detector._detect_outdated_versions(sample_scenarios)

        # v0.9.0 is outdated
        assert len(violations) >= 1
        assert all(v.type == ViolationType.OUTDATED_CONTRACT_VERSION for v in violations)

    def test_bdv_621_detect_failed_scenarios(self, sample_scenarios):
        """BDV-621: Detect failed scenarios (flaky vs real failures)"""
        detector = ViolationDetector()
        violations = detector._detect_failed_scenarios(sample_scenarios)

        # One failed scenario (flaky)
        assert len(violations) >= 1
        failed_violation = violations[0]
        assert failed_violation.type == ViolationType.FAILED_SCENARIO
        # Flaky failures should be WARNING, real failures ERROR
        assert failed_violation.severity == ViolationSeverity.WARNING  # It's flaky

    def test_bdv_622_detect_quarantined_scenarios(self, sample_scenarios):
        """BDV-622: Detect quarantined scenarios still in codebase"""
        detector = ViolationDetector()
        violations = detector._detect_quarantined_scenarios(sample_scenarios)

        # One quarantined scenario
        assert len(violations) >= 1
        assert all(v.type == ViolationType.QUARANTINED_SCENARIO for v in violations)
        assert all(v.severity == ViolationSeverity.INFO for v in violations)

    def test_bdv_623_detect_step_definition_conflicts(self, sample_step_definitions):
        """BDV-623: Detect step definition conflicts"""
        # Add duplicate step
        steps_with_duplicate = sample_step_definitions.copy()
        steps_with_duplicate.add('GIVEN I AM ON THE LOGIN PAGE')  # Duplicate (case insensitive)

        detector = ViolationDetector()
        violations = detector._detect_step_conflicts(steps_with_duplicate)

        # Should detect duplicate
        assert len(violations) >= 1
        assert all(v.type == ViolationType.STEP_DEFINITION_CONFLICT for v in violations)
        assert all(v.severity == ViolationSeverity.ERROR for v in violations)

    def test_bdv_624_detect_orphaned_step_definitions(
        self,
        sample_step_definitions,
        sample_step_usage
    ):
        """BDV-624: Detect orphaned step definitions (never used)"""
        detector = ViolationDetector()
        violations = detector._detect_orphaned_steps(
            sample_step_definitions,
            sample_step_usage
        )

        # "Given I am an admin user" is orphaned
        assert len(violations) >= 1
        assert all(v.type == ViolationType.ORPHANED_STEP for v in violations)
        assert all(v.severity == ViolationSeverity.INFO for v in violations)


# ============================================================================
# Test Suite 5: Integration & Performance (BDV-625 to BDV-630)
# ============================================================================

@pytest.mark.bdv
@pytest.mark.integration
class TestIntegrationPerformance:
    """Integration and performance tests (BDV-625 to BDV-630)"""

    def test_bdv_625_integration_with_bdv_runner(
        self,
        audit_engine,
        sample_scenarios
    ):
        """BDV-625: Integration with BDV Runner (fetch execution results)"""
        # BDV Runner would provide execution results
        # Audit engine processes them
        report = audit_engine.run_audit(sample_scenarios, {}, set(), set())

        # Should process BDV Runner results
        assert report.summary.total_scenarios == len(sample_scenarios)
        assert report.summary.passing >= 0
        assert report.summary.failing >= 0

    def test_bdv_626_integration_with_flake_detector(self, audit_engine):
        """BDV-626: Integration with FlakeDetector (quarantine data)"""
        # Mock flake detector
        mock_flake_detector = Mock()
        audit_engine.flake_detector = mock_flake_detector

        scenarios = [
            {'name': 'Flaky Test', 'status': 'failed', 'flaky': True, 'quarantined': True}
        ]

        report = audit_engine.run_audit(scenarios, {}, set(), set())

        # Should detect quarantined scenario
        quarantined_violations = [
            v for v in report.violations
            if v.type == ViolationType.QUARANTINED_SCENARIO
        ]
        assert len(quarantined_violations) >= 1

    def test_bdv_627_integration_with_contract_registry(
        self,
        audit_engine,
        mock_contract_registry,
        sample_scenarios
    ):
        """BDV-627: Integration with ContractRegistry (version validation)"""
        audit_engine.contract_registry = mock_contract_registry

        report = audit_engine.run_audit(sample_scenarios, {}, set(), set())

        # Should validate contracts against registry
        assert report.compliance.locked_contracts >= 0
        assert report.compliance.draft_contracts >= 0

    def test_bdv_628_audit_100_scenarios_performance(self, audit_engine):
        """BDV-628: Audit 100 scenarios in < 10 seconds"""
        # Generate 100 scenarios
        scenarios = []
        for i in range(100):
            scenarios.append({
                'name': f'Scenario {i}',
                'contract_tag': f'contract:API:v1.{i % 10}.0',
                'status': 'passed' if i % 5 != 0 else 'failed',
                'executed': True,
                'tested_endpoint': f'/endpoint{i % 20}',
                'file_path': f'features/test_{i}.feature',
                'flaky': False,
                'quarantined': False
            })

        start = time.time()
        report = audit_engine.run_audit(scenarios, {}, set(), set())
        elapsed = time.time() - start

        assert report.summary.total_scenarios == 100
        assert elapsed < 10.0, f"Audit took {elapsed:.2f}s, should be < 10s"

    def test_bdv_629_incremental_audit(
        self,
        audit_engine,
        sample_scenarios
    ):
        """BDV-629: Incremental audit (only changed scenarios)"""
        # Run initial audit
        initial_report = audit_engine.run_audit(sample_scenarios, {}, set(), set())

        # Run incremental audit on changed scenarios
        changed_scenarios = [sample_scenarios[0]]  # Only first scenario changed
        incremental_report = audit_engine.run_incremental_audit(
            changed_scenarios,
            initial_report
        )

        # Should be faster and only audit changed scenarios
        assert incremental_report is not None
        assert incremental_report.audit_id.startswith('bdv_audit_incremental_')

    def test_bdv_630_historical_comparison(
        self,
        audit_engine,
        sample_scenarios
    ):
        """BDV-630: Historical comparison (current vs previous audit)"""
        # Run multiple audits
        report1 = audit_engine.run_audit(sample_scenarios[:3], {}, set(), set())
        time.sleep(0.1)
        report2 = audit_engine.run_audit(sample_scenarios, {}, set(), set())

        # Calculate trends
        trends = audit_engine.coverage_calculator.calculate_historical_trends(
            [report1, report2]
        )

        # Should track historical trends
        assert len(trends) == 2
        assert trends[0].timestamp != trends[1].timestamp
        assert trends[0].scenario_coverage >= 0
        assert trends[1].scenario_coverage >= 0


# ============================================================================
# Integration Tests
# ============================================================================

@pytest.mark.bdv
@pytest.mark.integration
class TestBDVAuditIntegration:
    """End-to-end integration tests"""

    def test_full_audit_workflow(
        self,
        audit_engine,
        sample_scenarios,
        sample_openapi_specs,
        sample_step_definitions,
        sample_step_usage,
        tmp_path
    ):
        """Test complete audit workflow: analyze -> detect -> report -> save"""
        # 1. Run audit
        report = audit_engine.run_audit(
            sample_scenarios,
            sample_openapi_specs,
            sample_step_definitions,
            sample_step_usage
        )

        # 2. Validate report structure
        assert report.audit_id is not None
        assert report.coverage.scenario_coverage >= 0
        assert report.compliance.contract_compliance_score >= 0
        assert len(report.violations) >= 0

        # 3. Generate all report formats
        json_report = audit_engine.report_generator.generate_json_report(report)
        html_report = audit_engine.report_generator.generate_html_report(report)
        md_report = audit_engine.report_generator.generate_markdown_report(report)

        # 4. Save reports
        output_dir = tmp_path / "audit_reports"
        json_path = audit_engine.report_generator.save_report(report, "json", output_dir)
        html_path = audit_engine.report_generator.save_report(report, "html", output_dir)
        md_path = audit_engine.report_generator.save_report(report, "markdown", output_dir)

        # 5. Verify files created
        assert json_path.exists()
        assert html_path.exists()
        assert md_path.exists()


# ============================================================================
# Test Execution Summary
# ============================================================================

if __name__ == "__main__":
    import sys

    # Run pytest with verbose output
    exit_code = pytest.main([__file__, "-v", "--tb=short", "-ra"])

    print("\n" + "="*80)
    print("BDV Phase 2C - BDV Audit: Comprehensive Coverage & Compliance Tracking")
    print("="*80)
    print("\nTest Categories:")
    print("  1. Coverage Metrics (BDV-601 to BDV-606): 6 tests")
    print("  2. Contract Compliance (BDV-607 to BDV-612): 6 tests")
    print("  3. Audit Report Generation (BDV-613 to BDV-618): 6 tests")
    print("  4. Violation Detection (BDV-619 to BDV-624): 6 tests")
    print("  5. Integration & Performance (BDV-625 to BDV-630): 6 tests")
    print("   Integration tests: 1 test")
    print(f"\nTotal: 31 tests (30 required + 1 integration)")
    print("="*80)
    print("\nKey Implementations:")
    print("   BDVAuditEngine: Main audit orchestration")
    print("   CoverageCalculator: Scenario, endpoint, contract, step coverage")
    print("   ComplianceChecker: Contract version validation")
    print("   ViolationDetector: 6 violation types detected")
    print("   ReportGenerator: JSON, HTML, Markdown, PDF formats")
    print("   Coverage metrics: Scenario, endpoint, contract, step, requirement")
    print("   Compliance score: Contract compliance calculation")
    print("   Historical trends: Coverage tracking over time")
    print("   Performance: 100 scenarios audited in <10 seconds")
    print("   Incremental audit: Only changed scenarios")
    print("="*80)

    sys.exit(exit_code)
