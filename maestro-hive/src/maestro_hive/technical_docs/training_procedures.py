"""
EU AI Act Article 11 - Training/Fine-tuning Procedures Documentation.

EPIC: MD-2159 - [Compliance] Technical Documentation
AC-6: Document training/fine-tuning procedures

This module provides structures for documenting AI training
methodologies, data usage, and fine-tuning procedures.

AI DISCLOSURE: This code was generated by AI (Claude) for EU AI Act compliance purposes.
"""

from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Dict, List, Optional, Any
import json


class TrainingType(Enum):
    """Types of training/tuning approaches."""
    PRE_TRAINING = "pre_training"
    FINE_TUNING = "fine_tuning"
    PROMPT_ENGINEERING = "prompt_engineering"
    RLHF = "rlhf"
    RETRIEVAL_AUGMENTED = "retrieval_augmented"
    FEW_SHOT = "few_shot"
    ZERO_SHOT = "zero_shot"


class DataSourceType(Enum):
    """Types of training data sources."""
    PUBLIC_DATASET = "public_dataset"
    PROPRIETARY = "proprietary"
    SYNTHETIC = "synthetic"
    USER_GENERATED = "user_generated"
    CURATED = "curated"
    WEB_SCRAPED = "web_scraped"


class DataQualityLevel(Enum):
    """Quality levels for training data."""
    VERIFIED = "verified"
    REVIEWED = "reviewed"
    RAW = "raw"
    FILTERED = "filtered"


@dataclass
class TrainingDataset:
    """Documentation for a training dataset."""
    id: str
    name: str
    source_type: DataSourceType
    quality_level: DataQualityLevel
    description: str
    size_records: int
    size_bytes: int
    date_collected: datetime
    collection_methodology: str
    preprocessing_steps: List[str]
    contains_pii: bool
    pii_handling: str
    bias_assessment: str
    licensing: str
    retention_policy: str


@dataclass
class TrainingProcedure:
    """Documentation for a training procedure."""
    id: str
    name: str
    training_type: TrainingType
    description: str
    target_model: str
    datasets_used: List[str]
    hyperparameters: Dict[str, Any]
    training_duration: str
    compute_resources: str
    validation_approach: str
    success_criteria: List[str]
    output_artifacts: List[str]
    performed_by: str
    performed_date: datetime
    version: str


@dataclass
class PromptTemplate:
    """Documentation for a prompt engineering template."""
    id: str
    name: str
    purpose: str
    template: str
    variables: List[str]
    examples: List[Dict[str, str]]
    constraints: List[str]
    safety_guidelines: List[str]
    version: str
    created_at: datetime
    author: str


@dataclass
class TrainingDocumentation:
    """Complete training documentation."""
    id: str
    system_name: str
    version: str
    datasets: List[TrainingDataset]
    procedures: List[TrainingProcedure]
    prompt_templates: List[PromptTemplate]
    data_governance_policy: str
    quality_assurance_process: str
    created_at: datetime
    updated_at: datetime
    author: str


class TrainingDocumentationSystem:
    """
    System for documenting AI training procedures per EU AI Act.

    EU AI Act Article 11 Requirements:
    - Training methodologies and techniques
    - Training and validation datasets
    - Data governance and management
    - Design choices and assumptions
    """

    def __init__(self, system_name: str):
        self.system_name = system_name
        self.datasets: Dict[str, TrainingDataset] = {}
        self.procedures: Dict[str, TrainingProcedure] = {}
        self.prompt_templates: Dict[str, PromptTemplate] = {}
        self.version = "1.0.0"
        self.created_at = datetime.utcnow()

    def add_dataset(self, dataset: TrainingDataset) -> bool:
        """Add a training dataset documentation."""
        if dataset.id in self.datasets:
            return False
        self.datasets[dataset.id] = dataset
        return True

    def get_dataset(self, dataset_id: str) -> Optional[TrainingDataset]:
        """Retrieve a dataset by ID."""
        return self.datasets.get(dataset_id)

    def add_procedure(self, procedure: TrainingProcedure) -> bool:
        """Add a training procedure documentation."""
        if procedure.id in self.procedures:
            return False
        # Validate datasets exist
        for ds_id in procedure.datasets_used:
            if ds_id not in self.datasets:
                return False
        self.procedures[procedure.id] = procedure
        return True

    def get_procedure(self, procedure_id: str) -> Optional[TrainingProcedure]:
        """Retrieve a procedure by ID."""
        return self.procedures.get(procedure_id)

    def add_prompt_template(self, template: PromptTemplate) -> bool:
        """Add a prompt engineering template."""
        if template.id in self.prompt_templates:
            return False
        self.prompt_templates[template.id] = template
        return True

    def list_datasets(self, source_type: Optional[DataSourceType] = None) -> List[TrainingDataset]:
        """List all datasets, optionally filtered by source type."""
        datasets = list(self.datasets.values())
        if source_type:
            datasets = [d for d in datasets if d.source_type == source_type]
        return datasets

    def get_pii_datasets(self) -> List[TrainingDataset]:
        """Get datasets that contain PII."""
        return [d for d in self.datasets.values() if d.contains_pii]

    def list_procedures(self, training_type: Optional[TrainingType] = None) -> List[TrainingProcedure]:
        """List all procedures, optionally filtered by type."""
        procedures = list(self.procedures.values())
        if training_type:
            procedures = [p for p in procedures if p.training_type == training_type]
        return procedures

    def validate_data_governance(self) -> Dict[str, Any]:
        """Validate data governance compliance."""
        issues = []

        # Check PII handling
        pii_datasets = self.get_pii_datasets()
        for dataset in pii_datasets:
            if not dataset.pii_handling or dataset.pii_handling == "None":
                issues.append(f"Dataset {dataset.id} contains PII but lacks handling documentation")

        # Check bias assessments
        for dataset in self.datasets.values():
            if not dataset.bias_assessment:
                issues.append(f"Dataset {dataset.id} lacks bias assessment")

        # Check licensing
        for dataset in self.datasets.values():
            if not dataset.licensing:
                issues.append(f"Dataset {dataset.id} lacks licensing information")

        # Check retention policies
        for dataset in self.datasets.values():
            if not dataset.retention_policy:
                issues.append(f"Dataset {dataset.id} lacks retention policy")

        return {
            "valid": len(issues) == 0,
            "total_datasets": len(self.datasets),
            "pii_datasets": len(pii_datasets),
            "issues": issues
        }

    def validate_procedure_completeness(self, procedure_id: str) -> Dict[str, Any]:
        """Validate procedure documentation completeness."""
        procedure = self.procedures.get(procedure_id)
        if not procedure:
            return {"valid": False, "errors": ["Procedure not found"]}

        issues = []

        if not procedure.description or len(procedure.description) < 50:
            issues.append("Description too short")

        if len(procedure.datasets_used) == 0:
            issues.append("No datasets documented")

        if len(procedure.hyperparameters) == 0:
            issues.append("No hyperparameters documented")

        if not procedure.validation_approach:
            issues.append("Validation approach not documented")

        if len(procedure.success_criteria) == 0:
            issues.append("Success criteria not defined")

        return {
            "valid": len(issues) == 0,
            "procedure_id": procedure_id,
            "issues": issues
        }

    def get_data_lineage(self, procedure_id: str) -> Dict[str, Any]:
        """Get data lineage for a training procedure."""
        procedure = self.procedures.get(procedure_id)
        if not procedure:
            return {"error": "Procedure not found"}

        lineage = {
            "procedure": procedure_id,
            "training_type": procedure.training_type.value,
            "datasets": []
        }

        for ds_id in procedure.datasets_used:
            dataset = self.datasets.get(ds_id)
            if dataset:
                lineage["datasets"].append({
                    "id": ds_id,
                    "name": dataset.name,
                    "source_type": dataset.source_type.value,
                    "quality_level": dataset.quality_level.value,
                    "contains_pii": dataset.contains_pii,
                    "size_records": dataset.size_records
                })

        return lineage

    def generate_documentation(self) -> TrainingDocumentation:
        """Generate complete training documentation."""
        return TrainingDocumentation(
            id=f"td-{self.system_name.lower().replace(' ', '-')}",
            system_name=self.system_name,
            version=self.version,
            datasets=list(self.datasets.values()),
            procedures=list(self.procedures.values()),
            prompt_templates=list(self.prompt_templates.values()),
            data_governance_policy=self._generate_governance_summary(),
            quality_assurance_process=self._generate_qa_summary(),
            created_at=self.created_at,
            updated_at=datetime.utcnow(),
            author="system"
        )

    def _generate_governance_summary(self) -> str:
        """Generate data governance summary."""
        validation = self.validate_data_governance()
        return f"Data governance validated: {validation['valid']}. Total datasets: {validation['total_datasets']}. PII datasets: {validation['pii_datasets']}."

    def _generate_qa_summary(self) -> str:
        """Generate QA process summary."""
        verified = sum(1 for d in self.datasets.values() if d.quality_level == DataQualityLevel.VERIFIED)
        return f"Quality assurance: {verified}/{len(self.datasets)} datasets verified."

    def export_to_json(self) -> str:
        """Export all training documentation to JSON."""
        doc = self.generate_documentation()
        return json.dumps({
            "id": doc.id,
            "system_name": doc.system_name,
            "version": doc.version,
            "dataset_count": len(doc.datasets),
            "procedure_count": len(doc.procedures),
            "prompt_template_count": len(doc.prompt_templates),
            "data_governance": doc.data_governance_policy,
            "qa_process": doc.quality_assurance_process,
            "validation": self.validate_data_governance(),
            "created_at": doc.created_at.isoformat(),
            "updated_at": doc.updated_at.isoformat()
        }, indent=2)


def create_training_documentation_system(system_name: str = "Maestro AI Platform") -> TrainingDocumentationSystem:
    """Factory function to create a TrainingDocumentationSystem."""
    return TrainingDocumentationSystem(system_name)
